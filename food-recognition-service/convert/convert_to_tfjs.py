"""
å°‡è¨“ç·´å¥½çš„ TensorFlow æ¨¡å‹è½‰æ›ç‚º TensorFlow.js æ ¼å¼
"""
import os
import sys
import warnings
from pathlib import Path
import json
import subprocess

# ä¿®å¾© Windows æ§åˆ¶å°ç·¨ç¢¼å•é¡Œ
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# åœ¨å°å…¥ tensorflowjs ä¹‹å‰ï¼Œæ³¨å…¥å‡çš„æ¨¡å¡Šä¾†ç¹éå°å…¥éŒ¯èª¤
import types

# å‰µå»ºå‡çš„ decision_forests æ¨¡å¡Šï¼ˆå®Œæ•´çš„æ¨¡å¡Šçµæ§‹ï¼‰
fake_decision_forests = types.ModuleType('tensorflow_decision_forests')
fake_decision_forests.__version__ = "1.8.1"

# å‰µå»ºå‡çš„ keras å­æ¨¡å¡Š
fake_keras = types.ModuleType('tensorflow_decision_forests.keras')
fake_decision_forests.keras = fake_keras

# å‰µå»ºå‡çš„ tensorflow.ops.inference å­æ¨¡å¡Šï¼ˆé¿å…åŠ è¼‰ .so æ–‡ä»¶ï¼‰
fake_tf_ops = types.ModuleType('tensorflow_decision_forests.tensorflow')
fake_tf_ops_inference = types.ModuleType('tensorflow_decision_forests.tensorflow.ops')
fake_tf_ops_inference_api = types.ModuleType('tensorflow_decision_forests.tensorflow.ops.inference')
fake_tf_ops.ops = fake_tf_ops_inference
fake_tf_ops_inference.inference = fake_tf_ops_inference_api
fake_decision_forests.tensorflow = fake_tf_ops

# æ³¨å…¥åˆ° sys.modules
sys.modules['tensorflow_decision_forests'] = fake_decision_forests
sys.modules['tensorflow_decision_forests.keras'] = fake_keras
sys.modules['tensorflow_decision_forests.tensorflow'] = fake_tf_ops
sys.modules['tensorflow_decision_forests.tensorflow.ops'] = fake_tf_ops_inference
sys.modules['tensorflow_decision_forests.tensorflow.ops.inference'] = fake_tf_ops_inference_api

# ä¿®å¾© jax å°å…¥å•é¡Œï¼ˆå¦‚æœ jax ç‰ˆæœ¬å¤ªèˆŠï¼‰
try:
    import jax.experimental.jax2tf as jax2tf_module
    if not hasattr(jax2tf_module, 'shape_poly'):
        # å‰µå»ºå‡çš„ shape_poly å‡½æ•¸
        def fake_shape_poly(*args, **kwargs):
            return None
        jax2tf_module.shape_poly = fake_shape_poly
except (ImportError, AttributeError):
    # å¦‚æœå°å…¥å¤±æ•—ï¼Œå‰µå»ºå‡çš„æ¨¡å¡Š
    try:
        import types
        fake_jax2tf = types.ModuleType('jax.experimental.jax2tf')
        fake_jax2tf.shape_poly = lambda *args, **kwargs: None
        import jax.experimental
        jax.experimental.jax2tf = fake_jax2tf
        sys.modules['jax.experimental.jax2tf'] = fake_jax2tf
    except:
        pass

# è¨­ç½®ç’°å¢ƒè®Šé‡æ¸›å°‘è­¦å‘Š
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
warnings.filterwarnings('ignore')

def convert_h5_to_tfjs(h5_path, output_path):
    """
    å°‡ Keras H5 æ¨¡å‹è½‰æ›ç‚º TensorFlow.js æ ¼å¼
    
    Args:
        h5_path: Keras H5 æ¨¡å‹è·¯å¾‘
        output_path: TensorFlow.js è¼¸å‡ºè·¯å¾‘
    """
    print(f"ğŸ”„ è½‰æ› H5 æ¨¡å‹: {h5_path} -> {output_path}")
    
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    Path(output_path).mkdir(parents=True, exist_ok=True)
    
    try:
        # ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·è½‰æ› H5 æ¨¡å‹
        cmd = [
            sys.executable, '-m', 'tensorflowjs.converters.convert_keras',
            '--input_format=keras',
            '--output_format=tfjs_graph_model',
            str(h5_path),
            str(output_path)
        ]
        
        try:
            # ä½¿ç”¨åŒ…è£è…³æœ¬ä¾†é¿å…å°å…¥éŒ¯èª¤
            wrapper_script = Path(__file__).parent / 'convert_wrapper.py'
            if wrapper_script.exists():
                # ä½¿ç”¨åŒ…è£è…³æœ¬
                cmd = [sys.executable, str(wrapper_script)] + cmd[2:]  # è·³é python -m
            result = subprocess.run(cmd, check=True, capture_output=True, text=True)
            print(f"âœ… H5 æ¨¡å‹å·²è½‰æ›ç‚º TensorFlow.js æ ¼å¼: {output_path}")
            return True
        except subprocess.CalledProcessError as e:
            print(f"  å‘½ä»¤è¡Œè½‰æ›å¤±æ•—:")
            print(f"  éŒ¯èª¤ä»£ç¢¼: {e.returncode}")
            if e.stdout:
                print(f"  æ¨™æº–è¼¸å‡º: {e.stdout[:500]}")
            if e.stderr:
                print(f"  éŒ¯èª¤è¼¸å‡º: {e.stderr[:500]}")
            print(f"  è«‹æª¢æŸ¥ tensorflowjs æ˜¯å¦æ­£ç¢ºå®‰è£")
            return False
    except Exception as e:
        print(f"âŒ è½‰æ›å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def convert_model_to_tfjs(saved_model_path, output_path):
    """
    å°‡ TensorFlow SavedModel è½‰æ›ç‚º TensorFlow.js æ ¼å¼
    
    Args:
        saved_model_path: TensorFlow SavedModel è·¯å¾‘
        output_path: TensorFlow.js è¼¸å‡ºè·¯å¾‘
    """
    print(f"ğŸ”„ è½‰æ›æ¨¡å‹: {saved_model_path} -> {output_path}")
    
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    Path(output_path).mkdir(parents=True, exist_ok=True)
    
    try:
        # å„ªå…ˆä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·ï¼ˆé¿å… decision forests å°å…¥å•é¡Œï¼‰
        cmd = [
            sys.executable, '-m', 'tensorflowjs.converters.tf_saved_model_conversion_v2',
            '--input_format=tf_saved_model',
            '--saved_model_tags=serve',
            '--output_format=tfjs_graph_model',
            f'--saved_model_dir={str(saved_model_path)}',
            f'--output_dir={str(output_path)}'
        ]
        
        try:
            result = subprocess.run(cmd, check=True, capture_output=True, text=True)
            print(f"âœ… æ¨¡å‹å·²è½‰æ›ç‚º TensorFlow.js æ ¼å¼: {output_path}")
            return True
        except subprocess.CalledProcessError as e:
            print(f"  å‘½ä»¤è¡Œè½‰æ›å¤±æ•—:")
            print(f"  éŒ¯èª¤ä»£ç¢¼: {e.returncode}")
            if e.stdout:
                print(f"  æ¨™æº–è¼¸å‡º: {e.stdout[:500]}")
            if e.stderr:
                print(f"  éŒ¯èª¤è¼¸å‡º: {e.stderr[:500]}")
            print(f"  è«‹æª¢æŸ¥ tensorflowjs æ˜¯å¦æ­£ç¢ºå®‰è£")
            return False
    except Exception as e:
        print(f"âŒ è½‰æ›å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def convert_all_models():
    """è½‰æ›æ‰€æœ‰ä¸‰å±¤æ¨¡å‹"""
    base_dir = Path(__file__).parent.parent.parent  # å›åˆ° PartyBillCalculator æ ¹ç›®éŒ„
    models_dir = base_dir / 'models'  # ä½¿ç”¨å¯¦éš›çš„æ¨¡å‹ç›®éŒ„
    output_dir = base_dir / 'food-recognition-service' / 'models_tfjs'
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    output_dir.mkdir(parents=True, exist_ok=True)
    
    models_to_convert = [
        ('level1', 'ç¬¬ä¸€å±¤ï¼šé£Ÿç‰©æª¢æ¸¬'),
        ('level2', 'ç¬¬äºŒå±¤ï¼šèœç³»åˆ†é¡'),
        ('level3', 'ç¬¬ä¸‰å±¤ï¼šç´°ç²’åº¦åˆ†é¡')
    ]
    
    results = {}
    
    for level, description in models_to_convert:
        if level == 'level3':
            # level3 éœ€è¦è™•ç†æ¯å€‹åœ‹å®¶çš„æ¨¡å‹
            level3_dir = models_dir / 'level3'
            if not level3_dir.exists():
                print(f"âš ï¸  Level3 æ¨¡å‹ç›®éŒ„ä¸å­˜åœ¨: {level3_dir}")
                results[level] = False
                continue
            
            # æŸ¥æ‰¾æ‰€æœ‰åœ‹å®¶ç›®éŒ„
            countries = [d.name for d in level3_dir.iterdir() if d.is_dir()]
            if not countries:
                print(f"âš ï¸  Level3 æ²’æœ‰æ‰¾åˆ°åœ‹å®¶æ¨¡å‹ç›®éŒ„")
                results[level] = False
                continue
            
            print(f"\nğŸ“¦ {description}")
            level3_success = True
            for country in countries:
                model_path = level3_dir / country / 'final_model'
                output_path = output_dir / 'level3' / country
                
                if not model_path.exists():
                    print(f"  âš ï¸  {country} æ¨¡å‹ä¸å­˜åœ¨: {model_path}")
                    level3_success = False
                    continue
                
                print(f"  ğŸ”„ è½‰æ› {country} æ¨¡å‹...")
                success = convert_model_to_tfjs(str(model_path), str(output_path))
                if not success:
                    level3_success = False
            
            results[level] = level3_success
        else:
            # å…ˆå˜—è©¦æŸ¥æ‰¾ final_modelï¼ˆSavedModel æ ¼å¼ï¼‰
            model_path = models_dir / level / 'final_model'
            h5_path = models_dir / level / 'best_model.h5'
            output_path = output_dir / level
            
            print(f"\nğŸ“¦ {description}")
            
            # å¦‚æœå­˜åœ¨ SavedModel æ ¼å¼ï¼Œå„ªå…ˆä½¿ç”¨
            if model_path.exists():
                print(f"  æ‰¾åˆ° SavedModel æ ¼å¼: {model_path}")
                success = convert_model_to_tfjs(str(model_path), str(output_path))
                results[level] = success
            # å¦‚æœå­˜åœ¨ H5 æ ¼å¼ï¼Œè½‰æ› H5
            elif h5_path.exists():
                print(f"  æ‰¾åˆ° H5 æ ¼å¼: {h5_path}")
                print(f"  å°‡ H5 æ¨¡å‹è½‰æ›ç‚º TensorFlow.js æ ¼å¼...")
                success = convert_h5_to_tfjs(str(h5_path), str(output_path))
                results[level] = success
            else:
                print(f"âš ï¸  æ¨¡å‹ä¸å­˜åœ¨: {model_path} æˆ– {h5_path}")
                results[level] = False
    
    # ç¸½çµ
    print("\n" + "="*50)
    print("è½‰æ›ç¸½çµ:")
    for level, success in results.items():
        status = "âœ…" if success else "âŒ"
        print(f"  {status} {level}")
    
    # ç”Ÿæˆæ¨¡å‹ä¿¡æ¯æ–‡ä»¶
    info = {
        'models': {
            level: {
                'path': f'models_tfjs/{level}/model.json',
                'converted': success
            }
            for level, success in results.items()
        }
    }
    
    with open(output_dir / 'models_info.json', 'w') as f:
        json.dump(info, f, indent=2)
    
    print(f"\nğŸ“„ æ¨¡å‹ä¿¡æ¯å·²ä¿å­˜: {output_dir / 'models_info.json'}")

if __name__ == '__main__':
    # å˜—è©¦ä½¿ç”¨ç›´æ¥è½‰æ›æ–¹æ³•ï¼ˆæ¨è–¦ï¼‰
    try:
        print("å˜—è©¦ä½¿ç”¨ç›´æ¥è½‰æ›æ–¹æ³•...")
        from convert_direct import convert_all_models_direct
        convert_all_models_direct()
    except ImportError:
        print("ç›´æ¥è½‰æ›æ–¹æ³•ä¸å¯ç”¨ï¼Œä½¿ç”¨å‘½ä»¤è¡Œæ–¹æ³•...")
        convert_all_models()


