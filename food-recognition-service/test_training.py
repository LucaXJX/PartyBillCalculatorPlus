"""
Python è¨“ç·´åŠŸèƒ½æ¸¬è©¦è…³æœ¬
ä½¿ç”¨å°è¦æ¨¡æ•¸æ“šé›†é€²è¡Œå¿«é€Ÿæ¸¬è©¦ï¼Œé©—è­‰è¨“ç·´æµç¨‹æ˜¯å¦æ­£å¸¸
ä¸å½±éŸ¿ç¾æœ‰æ•¸æ“šåº«
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, callbacks
from tensorflow.keras.applications import MobileNetV2
from pathlib import Path
import numpy as np
import json
import shutil
import os

# è¨­ç½® GPU å…§å­˜å¢é•·ï¼ˆå¦‚æœä½¿ç”¨ GPUï¼‰
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print("âœ… GPU å·²é…ç½®")
    except RuntimeError as e:
        print(f"âš ï¸  GPU é…ç½®å¤±æ•—: {e}")

def create_test_data(data_dir: Path, num_samples_per_class: int = 20):
    """
    å‰µå»ºå°è¦æ¨¡æ¸¬è©¦æ•¸æ“šé›†
    
    Args:
        data_dir: æ•¸æ“šç›®éŒ„
        num_samples_per_class: æ¯å€‹é¡åˆ¥çš„æ¨£æœ¬æ•¸
    """
    print(f"ğŸ“¦ å‰µå»ºæ¸¬è©¦æ•¸æ“šé›†: {data_dir}")
    
    # å‰µå»ºç›®éŒ„çµæ§‹
    food_dir = data_dir / 'food'
    non_food_dir = data_dir / 'non_food'
    food_dir.mkdir(parents=True, exist_ok=True)
    non_food_dir.mkdir(parents=True, exist_ok=True)
    
    # ç”Ÿæˆéš¨æ©Ÿæ¸¬è©¦åœ–ç‰‡ï¼ˆä½¿ç”¨ TensorFlow å‰µå»ºï¼‰
    print(f"  ç”Ÿæˆ {num_samples_per_class} å€‹é£Ÿç‰©æ¨£æœ¬...")
    for i in range(num_samples_per_class):
        # å‰µå»ºéš¨æ©Ÿ RGB åœ–ç‰‡ (224x224x3)
        img = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
        
        # ä½¿ç”¨ PIL ä¿å­˜
        from PIL import Image
        img_pil = Image.fromarray(img)
        img_pil.save(food_dir / f'food_{i:04d}.jpg', 'JPEG')
    
    print(f"  ç”Ÿæˆ {num_samples_per_class} å€‹éé£Ÿç‰©æ¨£æœ¬...")
    for i in range(num_samples_per_class):
        img = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
        from PIL import Image
        img_pil = Image.fromarray(img)
        img_pil.save(non_food_dir / f'non_food_{i:04d}.jpg', 'JPEG')
    
    print(f"âœ… æ¸¬è©¦æ•¸æ“šé›†å·²å‰µå»º: {data_dir}")
    print(f"   é£Ÿç‰©æ¨£æœ¬: {num_samples_per_class}")
    print(f"   éé£Ÿç‰©æ¨£æœ¬: {num_samples_per_class}")

def build_test_model(input_shape=(224, 224, 3)):
    """æ§‹å»ºæ¸¬è©¦æ¨¡å‹ï¼ˆç°¡åŒ–ç‰ˆï¼Œç”¨æ–¼å¿«é€Ÿæ¸¬è©¦ï¼‰"""
    base_model = MobileNetV2(
        input_shape=input_shape,
        include_top=False,
        weights='imagenet'
    )
    base_model.trainable = False
    
    model = keras.Sequential([
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.Dense(64, activation='relu'),  # æ¸›å°‘åƒæ•¸ä»¥åŠ å¿«è¨“ç·´
        layers.Dropout(0.5),
        layers.Dense(1, activation='sigmoid')
    ])
    
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=0.001),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    return model

def test_training(data_dir: Path, model_dir: Path, epochs: int = 2):
    """
    æ¸¬è©¦è¨“ç·´æµç¨‹
    
    Args:
        data_dir: æ•¸æ“šç›®éŒ„
        model_dir: æ¨¡å‹ä¿å­˜ç›®éŒ„
        epochs: è¨“ç·´è¼ªæ•¸ï¼ˆæ¸¬è©¦æ™‚ä½¿ç”¨å°‘é‡è¼ªæ•¸ï¼‰
    """
    print("\n" + "="*60)
    print("ğŸ§ª é–‹å§‹æ¸¬è©¦è¨“ç·´æµç¨‹")
    print("="*60)
    
    # æª¢æŸ¥æ•¸æ“š
    if not data_dir.exists():
        print(f"âŒ æ•¸æ“šç›®éŒ„ä¸å­˜åœ¨: {data_dir}")
        return False
    
    # åŠ è¼‰æ•¸æ“š
    print("\nğŸ“¦ åŠ è¼‰è¨“ç·´æ•¸æ“š...")
    train_datagen = keras.preprocessing.image.ImageDataGenerator(
        rescale=1./255,
        validation_split=0.2
    )
    
    train_gen = train_datagen.flow_from_directory(
        str(data_dir),
        target_size=(224, 224),
        batch_size=8,  # å°æ‰¹é‡ä»¥åŠ å¿«æ¸¬è©¦
        class_mode='binary',
        subset='training'
    )
    
    val_gen = train_datagen.flow_from_directory(
        str(data_dir),
        target_size=(224, 224),
        batch_size=8,
        class_mode='binary',
        subset='validation'
    )
    
    print(f"  è¨“ç·´æ¨£æœ¬: {train_gen.samples}")
    print(f"  é©—è­‰æ¨£æœ¬: {val_gen.samples}")
    
    if train_gen.samples == 0:
        print("âŒ æ²’æœ‰æ‰¾åˆ°è¨“ç·´æ¨£æœ¬")
        return False
    
    # æ§‹å»ºæ¨¡å‹
    print("\nğŸ—ï¸  æ§‹å»ºæ¨¡å‹...")
    model = build_test_model()
    model.summary()
    
    # è¨“ç·´æ¨¡å‹
    print(f"\nğŸ¯ é–‹å§‹è¨“ç·´ï¼ˆ{epochs} å€‹ epochï¼‰...")
    model_dir.mkdir(parents=True, exist_ok=True)
    
    history = model.fit(
        train_gen,
        epochs=epochs,
        validation_data=val_gen,
        verbose=1
    )
    
    # ä¿å­˜æ¨¡å‹
    print("\nğŸ’¾ ä¿å­˜æ¨¡å‹...")
    final_model_path = model_dir / 'final_model'
    model.save(str(final_model_path))
    
    # ä¿å­˜è¨“ç·´æ­·å²
    history_path = model_dir / 'training_history.json'
    with open(history_path, 'w') as f:
        json.dump({k: [float(v) for v in values] for k, values in history.history.items()}, f, indent=2)
    
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {final_model_path}")
    print(f"âœ… è¨“ç·´æ­·å²å·²ä¿å­˜: {history_path}")
    
    # é©—è­‰æ¨¡å‹æ–‡ä»¶
    if not final_model_path.exists():
        print("âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    # æª¢æŸ¥ SavedModel çµæ§‹
    saved_model_pb = final_model_path / 'saved_model.pb'
    if not saved_model_pb.exists():
        print("âš ï¸  è­¦å‘Š: saved_model.pb ä¸å­˜åœ¨ï¼Œå¯èƒ½ä¸æ˜¯ SavedModel æ ¼å¼")
    else:
        print("âœ… SavedModel æ ¼å¼æ­£ç¢º")
    
    return True

def test_model_conversion(model_dir: Path, output_dir: Path):
    """
    æ¸¬è©¦æ¨¡å‹è½‰æ›
    
    Args:
        model_dir: åŸå§‹æ¨¡å‹ç›®éŒ„
        output_dir: TensorFlow.js è¼¸å‡ºè·¯å¾‘
    """
    print("\n" + "="*60)
    print("ğŸ”„ æ¸¬è©¦æ¨¡å‹è½‰æ›")
    print("="*60)
    
    # è¨­ç½®ç’°å¢ƒè®Šé‡ä¾†è·³é decision forestsï¼ˆWindows ä¸Šå¯èƒ½ç¼ºå°‘ native åº«ï¼‰
    import os
    import sys
    from types import ModuleType
    
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # æ¸›å°‘è­¦å‘Š
    
    # å¦‚æœ decision forests ä¸å­˜åœ¨ï¼Œå‰µå»ºä¸€å€‹å‡çš„æ¨¡å¡Šä¾†æ»¿è¶³ tensorflowjs çš„å°å…¥éœ€æ±‚
    if 'tensorflow_decision_forests' not in sys.modules:
        try:
            import tensorflow_decision_forests
        except (ImportError, ModuleNotFoundError):
            # å‰µå»ºå‡çš„æ¨¡å¡Š
            fake_module = ModuleType('tensorflow_decision_forests')
            fake_keras = ModuleType('tensorflow_decision_forests.keras')
            fake_module.keras = fake_keras
            sys.modules['tensorflow_decision_forests'] = fake_module
            sys.modules['tensorflow_decision_forests.keras'] = fake_keras
    
    try:
        # å˜—è©¦å»¶é²å°å…¥ï¼Œé¿å… decision forests å•é¡Œ
        import warnings
        warnings.filterwarnings('ignore')
        
        # ç›´æ¥ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·è€Œä¸æ˜¯ Python APIï¼ˆæ›´å¯é ï¼‰
        import subprocess
        
        model_path = model_dir / 'final_model'
        if not model_path.exists():
            print(f"âŒ æ¨¡å‹ä¸å­˜åœ¨: {model_path}")
            return False
        
        output_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"  è½‰æ›: {model_path} -> {output_dir}")
        print("  (ä½¿ç”¨ tensorflowjs_converter å‘½ä»¤è¡Œå·¥å…·)")
        
        # ä½¿ç”¨ tensorflowjs_converter å‘½ä»¤è¡Œå·¥å…·
        cmd = [
            sys.executable, '-m', 'tensorflowjs.converters.tf_saved_model_conversion_v2',
            '--input_format=tf_saved_model',
            f'--saved_model_tags=serve',
            f'--output_format=tfjs_graph_model',
            f'--saved_model_dir={str(model_path)}',
            f'--output_dir={str(output_dir)}'
        ]
        
        try:
            # è¨­ç½®ç’°å¢ƒè®Šé‡æ¸›å°‘è­¦å‘Š
            env = os.environ.copy()
            env['TF_CPP_MIN_LOG_LEVEL'] = '3'
            env['PYTHONWARNINGS'] = 'ignore'
            
            result = subprocess.run(cmd, capture_output=True, text=True, check=False, env=env)
            
            # å³ä½¿å‘½ä»¤è¿”å›éŒ¯èª¤ï¼Œä¹Ÿæª¢æŸ¥æ˜¯å¦ç”Ÿæˆäº†æ–‡ä»¶ï¼ˆdecision forests è­¦å‘Šä¸å½±éŸ¿è½‰æ›ï¼‰
            model_json = output_dir / 'model.json'
            if model_json.exists():
                print("âœ… æ¨¡å‹è½‰æ›æˆåŠŸ")
                print(f"âœ… TensorFlow.js æ¨¡å‹æ–‡ä»¶å·²ç”Ÿæˆ: {model_json}")
                return True
            else:
                # å¦‚æœæ²’æœ‰ç”Ÿæˆæ–‡ä»¶ï¼Œé¡¯ç¤ºéŒ¯èª¤ï¼ˆéæ¿¾æ‰ decision forests è­¦å‘Šï¼‰
                if result.stderr:
                    error_lines = [
                        line for line in result.stderr.split('\n')
                        if 'decision_forests' not in line.lower()
                        and 'inference.so' not in line.lower()
                        and line.strip()
                        and 'warning' not in line.lower()
                    ]
                    if error_lines:
                        print(f"âŒ è½‰æ›å¤±æ•—:")
                        for line in error_lines[-3:]:
                            print(f"   {line[:100]}")
                print("âŒ model.json ä¸å­˜åœ¨")
                return False
        except subprocess.CalledProcessError as e:
            # å³ä½¿æœ‰éŒ¯èª¤ï¼Œä¹Ÿæª¢æŸ¥æ˜¯å¦ç”Ÿæˆäº†æ–‡ä»¶ï¼ˆdecision forests è­¦å‘Šä¸å½±éŸ¿è½‰æ›ï¼‰
            model_json = output_dir / 'model.json'
            if model_json.exists():
                print("âš ï¸  è½‰æ›éç¨‹æœ‰è­¦å‘Šï¼Œä½†æ¨¡å‹æ–‡ä»¶å·²ç”Ÿæˆ")
                print(f"âœ… TensorFlow.js æ¨¡å‹æ–‡ä»¶: {model_json}")
                return True
            
            print(f"âŒ è½‰æ›å¤±æ•—ï¼ˆå‘½ä»¤è¡Œï¼‰")
            # å˜—è©¦ä½¿ç”¨å¸¶å‡æ¨¡å¡Šæ³¨å…¥çš„è½‰æ›è…³æœ¬
            print("  å˜—è©¦ä½¿ç”¨æ”¹é€²çš„è½‰æ›è…³æœ¬ï¼ˆæ³¨å…¥å‡æ¨¡å¡Šï¼‰...")
            try:
                convert_script = Path(__file__).parent / 'convert_with_fake_modules.py'
                if convert_script.exists():
                    result = subprocess.run(
                        [sys.executable, str(convert_script), str(model_path), str(output_dir)],
                        capture_output=True,
                        text=True,
                        env=env
                    )
                    if (output_dir / 'model.json').exists():
                        print("âœ… æ¨¡å‹è½‰æ›æˆåŠŸï¼ˆæ”¹é€²è…³æœ¬ï¼‰")
                        return True
                    elif result.stdout and 'SUCCESS' in result.stdout:
                        print("âœ… æ¨¡å‹è½‰æ›æˆåŠŸï¼ˆæ”¹é€²è…³æœ¬ï¼‰")
                        return True
                
                return False
            except Exception as e2:
                print(f"âŒ æ”¹é€²è…³æœ¬ä¹Ÿå¤±æ•—: {e2}")
                return False
                
    except ImportError:
        print("âŒ tensorflowjs æœªå®‰è£ï¼Œè«‹é‹è¡Œ: pip install tensorflowjs")
        return False
    except Exception as e:
        print(f"âŒ è½‰æ›å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False
    

def main():
    """ä¸»æ¸¬è©¦æµç¨‹"""
    print("="*60)
    print("ğŸ§ª Python è¨“ç·´åŠŸèƒ½æ¸¬è©¦")
    print("="*60)
    print("\næ­¤æ¸¬è©¦å°‡ï¼š")
    print("1. å‰µå»ºå°è¦æ¨¡æ¸¬è©¦æ•¸æ“šé›†")
    print("2. è¨“ç·´ä¸€å€‹ç°¡åŒ–æ¨¡å‹ï¼ˆå°‘é‡ epochï¼‰")
    print("3. æ¸¬è©¦æ¨¡å‹è½‰æ›ç‚º TensorFlow.js")
    print("4. é©—è­‰æ‰€æœ‰æ–‡ä»¶æ˜¯å¦æ­£ç¢ºç”Ÿæˆ")
    print("\nâš ï¸  æ³¨æ„ï¼šæ­¤æ¸¬è©¦ä¸æœƒå½±éŸ¿ç¾æœ‰æ•¸æ“šåº«æˆ–ç”Ÿç”¢æ•¸æ“š")
    
    base_dir = Path(__file__).parent
    test_data_dir = base_dir / 'test_data' / 'level1'
    test_model_dir = base_dir / 'test_models' / 'level1'
    test_output_dir = base_dir / 'test_models_tfjs' / 'level1'
    
    # æ¸…ç†èˆŠçš„æ¸¬è©¦æ•¸æ“šï¼ˆå¯é¸ï¼‰
    if test_data_dir.exists() and input("\næ˜¯å¦æ¸…ç†èˆŠçš„æ¸¬è©¦æ•¸æ“šï¼Ÿ(y/N): ").lower() == 'y':
        print("ğŸ§¹ æ¸…ç†èˆŠæ¸¬è©¦æ•¸æ“š...")
        if test_data_dir.exists():
            shutil.rmtree(test_data_dir)
        if test_model_dir.exists():
            shutil.rmtree(test_model_dir)
        if test_output_dir.exists():
            shutil.rmtree(test_output_dir)
    
    results = {
        'data_creation': False,
        'training': False,
        'conversion': False
    }
    
    # æ­¥é©Ÿ 1: å‰µå»ºæ¸¬è©¦æ•¸æ“š
    print("\n" + "="*60)
    print("æ­¥é©Ÿ 1: å‰µå»ºæ¸¬è©¦æ•¸æ“š")
    print("="*60)
    try:
        create_test_data(test_data_dir, num_samples_per_class=20)
        results['data_creation'] = True
    except Exception as e:
        print(f"âŒ å‰µå»ºæ¸¬è©¦æ•¸æ“šå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # æ­¥é©Ÿ 2: æ¸¬è©¦è¨“ç·´
    print("\n" + "="*60)
    print("æ­¥é©Ÿ 2: æ¸¬è©¦è¨“ç·´")
    print("="*60)
    try:
        results['training'] = test_training(test_data_dir, test_model_dir, epochs=2)
    except Exception as e:
        print(f"âŒ è¨“ç·´å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
    
    # æ­¥é©Ÿ 3: æ¸¬è©¦è½‰æ›
    if results['training']:
        print("\n" + "="*60)
        print("æ­¥é©Ÿ 3: æ¸¬è©¦æ¨¡å‹è½‰æ›")
        print("="*60)
        try:
            results['conversion'] = test_model_conversion(test_model_dir, test_output_dir)
        except Exception as e:
            print(f"âŒ è½‰æ›å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
    
    # ç¸½çµ
    print("\n" + "="*60)
    print("ğŸ“Š æ¸¬è©¦ç¸½çµ")
    print("="*60)
    for step, success in results.items():
        status = "âœ…" if success else "âŒ"
        step_name = {
            'data_creation': 'æ•¸æ“šå‰µå»º',
            'training': 'æ¨¡å‹è¨“ç·´',
            'conversion': 'æ¨¡å‹è½‰æ›'
        }.get(step, step)
        print(f"  {status} {step_name}")
    
    # è¨“ç·´æˆåŠŸæ˜¯æœ€é‡è¦çš„ï¼Œè½‰æ›å•é¡Œå¯ä»¥å¾ŒçºŒè§£æ±º
    training_success = results['training'] and results['data_creation']
    conversion_success = results['conversion']
    all_passed = training_success and conversion_success
    
    if training_success:
        print("\nğŸ‰ æ ¸å¿ƒåŠŸèƒ½æ¸¬è©¦é€šéï¼Python è¨“ç·´æµç¨‹æ­£å¸¸å·¥ä½œã€‚")
        print(f"\nğŸ“ æ¸¬è©¦æ–‡ä»¶ä½ç½®ï¼š")
        print(f"   æ•¸æ“š: {test_data_dir}")
        print(f"   æ¨¡å‹: {test_model_dir}")
        if conversion_success:
            print(f"   TensorFlow.js: {test_output_dir}")
        else:
            print(f"   TensorFlow.js: (è½‰æ›å¤±æ•—ï¼Œä½†æ¨¡å‹å·²ä¿å­˜)")
        
        if not conversion_success:
            print("\nâš ï¸  æ¨¡å‹è½‰æ›å¤±æ•—ï¼ˆä¾è³´å…¼å®¹æ€§å•é¡Œï¼‰")
            print("ğŸ’¡ è§£æ±ºæ–¹æ¡ˆï¼š")
            print("   1. è½‰æ›å•é¡Œä¸å½±éŸ¿è¨“ç·´åŠŸèƒ½ï¼Œè¨“ç·´å·²æˆåŠŸé©—è­‰")
            print("   2. å¯ä»¥æš«æ™‚è·³éè½‰æ›æ¸¬è©¦ï¼Œç¹¼çºŒé€²è¡Œæ•¸æ“šåº« schema å·¥ä½œ")
            print("   3. è½‰æ›å¯ä»¥åœ¨å¯¦éš›éœ€è¦æ™‚å†è§£æ±ºï¼ˆä½¿ç”¨å…¶ä»–è½‰æ›å·¥å…·æˆ–æ›´æ–°ä¾è³´ï¼‰")
            print("   4. è¨“ç·´å¥½çš„æ¨¡å‹ï¼ˆSavedModel æ ¼å¼ï¼‰å¯ä»¥ç›´æ¥ä½¿ç”¨")
        
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥ï¼š")
        print("   1. æº–å‚™çœŸå¯¦è¨“ç·´æ•¸æ“š")
        print("   2. é‹è¡Œå®Œæ•´è¨“ç·´è…³æœ¬")
        if conversion_success:
            print("   3. è½‰æ›æ¨¡å‹ä¸¦åœ¨ Node.js ä¸­ä½¿ç”¨")
        else:
            print("   3. è½‰æ›å•é¡Œå¯ä»¥å¾ŒçºŒè§£æ±ºï¼Œä¸å½±éŸ¿è¨“ç·´åŠŸèƒ½")
    else:
        print("\nâš ï¸  æ ¸å¿ƒåŠŸèƒ½æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤ä¿¡æ¯ã€‚")
    
    return all_passed

if __name__ == '__main__':
    main()

