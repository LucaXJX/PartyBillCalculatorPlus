"""
ç¬¬ä¸‰å±¤æ¨¡å‹è¨“ç·´ï¼šç´°ç²’åº¦é£Ÿç‰©åˆ†é¡ï¼ˆæŒ‰åœ‹å®¶/èœç³»ï¼‰
"""
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, callbacks
from tensorflow.keras.applications import MobileNetV2
from pathlib import Path
import json
import sys

# è¨­ç½® GPU å…§å­˜å¢é•·
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
    except RuntimeError as e:
        print(e)

def build_fine_grained_model(input_shape=(224, 224, 3), num_classes=10):
    """
    æ§‹å»ºç´°ç²’åº¦åˆ†é¡æ¨¡å‹
    
    Args:
        input_shape: è¼¸å…¥åœ–åƒå½¢ç‹€
        num_classes: åˆ†é¡æ•¸é‡
        
    Returns:
        ç·¨è­¯å¥½çš„æ¨¡å‹
    """
    base_model = MobileNetV2(
        input_shape=input_shape,
        include_top=False,
        weights='imagenet'
    )
    
    base_model.trainable = False
    
    model = keras.Sequential([
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.Dense(512, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.3),
        layers.Dense(num_classes, activation='softmax')
    ])
    
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=0.001),
        loss='categorical_crossentropy',
        metrics=['accuracy', 'top_k_categorical_accuracy']
    )
    
    return model

def load_data(data_dir):
    """åŠ è¼‰è¨“ç·´æ•¸æ“š"""
    train_datagen = keras.preprocessing.image.ImageDataGenerator(
        rescale=1./255,
        rotation_range=30,
        width_shift_range=0.3,
        height_shift_range=0.3,
        horizontal_flip=True,
        zoom_range=0.2,
        brightness_range=[0.8, 1.2],
        validation_split=0.2
    )
    
    train_generator = train_datagen.flow_from_directory(
        data_dir,
        target_size=(224, 224),
        batch_size=32,
        class_mode='categorical',
        subset='training'
    )
    
    val_generator = train_datagen.flow_from_directory(
        data_dir,
        target_size=(224, 224),
        batch_size=32,
        class_mode='categorical',
        subset='validation'
    )
    
    return train_generator, val_generator

def train_level3(country='chinese'):
    """
    è¨“ç·´ç¬¬ä¸‰å±¤æ¨¡å‹ï¼ˆæŒ‰åœ‹å®¶/èœç³»ï¼‰
    
    Args:
        country: åœ‹å®¶/èœç³»åç¨±ï¼ˆå¦‚ 'chinese', 'japanese'ï¼‰
    """
    print(f"ğŸš€ é–‹å§‹è¨“ç·´ç¬¬ä¸‰å±¤æ¨¡å‹ï¼š{country} ç´°ç²’åº¦åˆ†é¡")
    
    data_dir = Path(f'../data/level3/{country}')
    model_dir = Path(f'../models/level3/{country}')
    model_dir.mkdir(parents=True, exist_ok=True)
    
    if not data_dir.exists():
        print(f"âŒ æ•¸æ“šç›®éŒ„ä¸å­˜åœ¨: {data_dir}")
        print(f"è«‹å…ˆæº–å‚™ {country} çš„è¨“ç·´æ•¸æ“š")
        return
    
    print("ğŸ“¦ åŠ è¼‰è¨“ç·´æ•¸æ“š...")
    train_gen, val_gen = load_data(str(data_dir))
    
    num_classes = len(train_gen.class_indices)
    print(f"åˆ†é¡æ•¸é‡: {num_classes}")
    print(f"é¡åˆ¥: {train_gen.class_indices}")
    print(f"è¨“ç·´æ¨£æœ¬æ•¸: {train_gen.samples}")
    print(f"é©—è­‰æ¨£æœ¬æ•¸: {val_gen.samples}")
    
    # ä¿å­˜é¡åˆ¥æ˜ å°„
    with open(model_dir / 'class_indices.json', 'w') as f:
        json.dump(train_gen.class_indices, f, indent=2)
    
    print("ğŸ—ï¸  æ§‹å»ºæ¨¡å‹...")
    model = build_fine_grained_model(num_classes=num_classes)
    model.summary()
    
    callbacks_list = [
        callbacks.ModelCheckpoint(
            str(model_dir / 'best_model.h5'),
            monitor='val_accuracy',
            save_best_only=True,
            verbose=1
        ),
        callbacks.EarlyStopping(
            monitor='val_accuracy',
            patience=5,
            restore_best_weights=True,
            verbose=1
        ),
        callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=3,
            verbose=1
        )
    ]
    
    print("ğŸ¯ é–‹å§‹è¨“ç·´...")
    history = model.fit(
        train_gen,
        epochs=50,
        validation_data=val_gen,
        callbacks=callbacks_list,
        verbose=1
    )
    
    print("ğŸ’¾ ä¿å­˜æ¨¡å‹...")
    model.save(str(model_dir / 'final_model'))
    
    with open(model_dir / 'training_history.json', 'w') as f:
        json.dump(history.history, f, indent=2)
    
    print("âœ… è¨“ç·´å®Œæˆï¼")
    print(f"æ¨¡å‹ä¿å­˜åœ¨: {model_dir / 'final_model'}")

if __name__ == '__main__':
    # å¯ä»¥é€šéå‘½ä»¤è¡Œåƒæ•¸æŒ‡å®šåœ‹å®¶
    country = sys.argv[1] if len(sys.argv) > 1 else 'chinese'
    train_level3(country)


