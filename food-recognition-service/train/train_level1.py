"""
ç¬¬ä¸€å±¤æ¨¡å‹è¨“ç·´ï¼šé£Ÿç‰©æª¢æ¸¬ï¼ˆäºŒåˆ†é¡ï¼šæ˜¯é£Ÿç‰©/ä¸æ˜¯é£Ÿç‰©ï¼‰
"""
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, callbacks
from tensorflow.keras.applications import MobileNetV2
import numpy as np
from pathlib import Path
import os

# è¨­ç½® GPU å…§å­˜å¢é•·ï¼ˆå¦‚æœä½¿ç”¨ GPUï¼‰
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
    except RuntimeError as e:
        print(e)

def build_food_detection_model(input_shape=(224, 224, 3)):
    """
    æ§‹å»ºé£Ÿç‰©æª¢æ¸¬æ¨¡å‹
    
    Args:
        input_shape: è¼¸å…¥åœ–åƒå½¢ç‹€
        
    Returns:
        ç·¨è­¯å¥½çš„æ¨¡å‹
    """
    # ä½¿ç”¨ MobileNetV2 ä½œç‚ºåŸºç¤æ¨¡å‹ï¼ˆé·ç§»å­¸ç¿’ï¼‰
    base_model = MobileNetV2(
        input_shape=input_shape,
        include_top=False,
        weights='imagenet'
    )
    
    # å‡çµåŸºç¤æ¨¡å‹ï¼ˆå¯é¸ï¼šå…ˆå‡çµè¨“ç·´åˆ†é¡å±¤ï¼Œç„¶å¾Œè§£å‡å¾®èª¿ï¼‰
    base_model.trainable = False
    
    # æ§‹å»ºå®Œæ•´æ¨¡å‹
    model = keras.Sequential([
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(1, activation='sigmoid')  # äºŒåˆ†é¡ï¼šæ˜¯é£Ÿç‰©(1) / ä¸æ˜¯é£Ÿç‰©(0)
    ])
    
    # ç·¨è­¯æ¨¡å‹
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=0.001),
        loss='binary_crossentropy',
        metrics=['accuracy', 'precision', 'recall']
    )
    
    return model

def load_data(data_dir):
    """
    åŠ è¼‰è¨“ç·´æ•¸æ“š
    
    Args:
        data_dir: æ•¸æ“šç›®éŒ„è·¯å¾‘
        
    Returns:
        (train_dataset, val_dataset, test_dataset)
    """
    # TODO: å¯¦ç¾æ•¸æ“šåŠ è¼‰é‚è¼¯
    # æ•¸æ“šçµæ§‹ï¼š
    # data_dir/
    #   â”œâ”€â”€ food/          # é£Ÿç‰©åœ–ç‰‡
    #   â””â”€â”€ non_food/      # éé£Ÿç‰©åœ–ç‰‡
    
    # ä½¿ç”¨ ImageDataGenerator é€²è¡Œæ•¸æ“šåŠ è¼‰å’Œå¢å¼·
    train_datagen = keras.preprocessing.image.ImageDataGenerator(
        rescale=1./255,
        rotation_range=20,
        width_shift_range=0.2,
        height_shift_range=0.2,
        horizontal_flip=True,
        validation_split=0.2
    )
    
    train_generator = train_datagen.flow_from_directory(
        data_dir,
        target_size=(224, 224),
        batch_size=32,
        class_mode='binary',
        subset='training'
    )
    
    val_generator = train_datagen.flow_from_directory(
        data_dir,
        target_size=(224, 224),
        batch_size=32,
        class_mode='binary',
        subset='validation'
    )
    
    return train_generator, val_generator

def train_level1():
    """è¨“ç·´ç¬¬ä¸€å±¤æ¨¡å‹"""
    print("ğŸš€ é–‹å§‹è¨“ç·´ç¬¬ä¸€å±¤æ¨¡å‹ï¼šé£Ÿç‰©æª¢æ¸¬")
    
    # è¨­ç½®è·¯å¾‘
    data_dir = Path('../data/level1')  # æ•¸æ“šç›®éŒ„
    model_dir = Path('../models/level1')
    model_dir.mkdir(parents=True, exist_ok=True)
    
    # æª¢æŸ¥æ•¸æ“šç›®éŒ„
    if not data_dir.exists():
        print(f"âŒ æ•¸æ“šç›®éŒ„ä¸å­˜åœ¨: {data_dir}")
        print("è«‹å…ˆæº–å‚™è¨“ç·´æ•¸æ“š")
        return
    
    # åŠ è¼‰æ•¸æ“š
    print("ğŸ“¦ åŠ è¼‰è¨“ç·´æ•¸æ“š...")
    train_gen, val_gen = load_data(str(data_dir))
    
    print(f"è¨“ç·´æ¨£æœ¬æ•¸: {train_gen.samples}")
    print(f"é©—è­‰æ¨£æœ¬æ•¸: {val_gen.samples}")
    
    # æ§‹å»ºæ¨¡å‹
    print("ğŸ—ï¸  æ§‹å»ºæ¨¡å‹...")
    model = build_food_detection_model()
    model.summary()
    
    # å®šç¾©å›èª¿
    callbacks_list = [
        callbacks.ModelCheckpoint(
            str(model_dir / 'best_model.h5'),
            monitor='val_accuracy',
            save_best_only=True,
            verbose=1
        ),
        callbacks.EarlyStopping(
            monitor='val_accuracy',
            patience=5,
            restore_best_weights=True,
            verbose=1
        ),
        callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=3,
            verbose=1
        )
    ]
    
    # è¨“ç·´æ¨¡å‹
    print("ğŸ¯ é–‹å§‹è¨“ç·´...")
    history = model.fit(
        train_gen,
        epochs=50,
        validation_data=val_gen,
        callbacks=callbacks_list,
        verbose=1
    )
    
    # ä¿å­˜æœ€çµ‚æ¨¡å‹
    print("ğŸ’¾ ä¿å­˜æ¨¡å‹...")
    model.save(str(model_dir / 'final_model'))
    
    # ä¿å­˜è¨“ç·´æ­·å²
    import json
    with open(model_dir / 'training_history.json', 'w') as f:
        json.dump(history.history, f, indent=2)
    
    print("âœ… è¨“ç·´å®Œæˆï¼")
    print(f"æ¨¡å‹ä¿å­˜åœ¨: {model_dir / 'final_model'}")
    
    return model

if __name__ == '__main__':
    train_level1()


