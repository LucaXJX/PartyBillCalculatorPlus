# é£Ÿç‰©åœ–ç‰‡è­˜åˆ¥ç³»çµ±æ¶æ§‹è¨­è¨ˆ

## æ¦‚è¿°

æœ¬æ–‡æª”æè¿°åŸºæ–¼ TensorFlow çš„åˆ†å±¤é£Ÿç‰©è­˜åˆ¥ç³»çµ±æ¶æ§‹è¨­è¨ˆã€‚ç³»çµ±æ¡ç”¨ä¸‰å±¤ç´šè¯åˆ†é¡æ¶æ§‹ï¼Œå¾ç²—ç²’åº¦åˆ°ç´°ç²’åº¦é€æ­¥è­˜åˆ¥é£Ÿç‰©åœ–åƒã€‚

## è¨­è¨ˆæŒ‡å°åŸå‰‡

**è€å¸«å»ºè­°**ï¼š

> "æœ€å¥½èƒ½è¨“ç·´ä¸€å€‹æ–°çš„æ¨¡å‹ï¼Œæ§‹å»ºä¸€äº›ç¾æœ‰ AI ç„¡æ³•ç›´æ¥è§£æ±ºçš„å•é¡Œã€‚ä½¿ç”¨ç¾æœ‰æ¨¡å‹å¯ä»¥ä½œç‚ºå‚™é¸æ–¹æ¡ˆã€‚"

**ç†è§£èˆ‡ç¸½çµ**ï¼š

1. **å„ªå…ˆç›®æ¨™**ï¼šè¨“ç·´è‡ªå®šç¾©æ¨¡å‹

   - ä¸ä¾è³´ç¾æˆçš„ API æˆ–é è¨“ç·´æ¨¡å‹ç›´æ¥æ‡‰ç”¨
   - é‡å°ç‰¹å®šå ´æ™¯å’Œéœ€æ±‚ï¼Œå¾é›¶é–‹å§‹æˆ–åŸºæ–¼é·ç§»å­¸ç¿’è¨“ç·´å°ˆç”¨æ¨¡å‹
   - è§£æ±ºç¾æœ‰é€šç”¨ AI æ¨¡å‹ç„¡æ³•ç›´æ¥è§£æ±ºçš„ç‰¹å®šå•é¡Œ

2. **æ ¸å¿ƒåƒ¹å€¼**ï¼š

   - **å‰µæ–°æ€§**ï¼šæ§‹å»ºèƒ½è§£æ±ºç¾æœ‰ AI ç„¡æ³•ç›´æ¥è§£æ±ºçš„å•é¡Œçš„ç³»çµ±
   - **é‡å°æ€§**ï¼šé‡å°æœ¬åœ°é£Ÿç‰©ã€ç‰¹å®šå ´æ™¯ï¼ˆå¦‚èšæœƒè³¬å–®ä¸­çš„é£Ÿç‰©è­˜åˆ¥ï¼‰é€²è¡Œå„ªåŒ–
   - **æ•™è‚²æ„ç¾©**ï¼šé€šéå¯¦éš›è¨“ç·´éç¨‹ï¼Œæ·±å…¥ç†è§£æ·±åº¦å­¸ç¿’å’Œåœ–åƒè­˜åˆ¥

3. **å‚™é¸æ–¹æ¡ˆ**ï¼š

   - ç¾æœ‰æ¨¡å‹ï¼ˆå¦‚ç™¾åº¦ APIã€Google Vision APIï¼‰ä½œç‚ºå‚™é¸æˆ–è¼”åŠ©æ–¹æ¡ˆ
   - åœ¨è‡ªè¨“ç·´æ¨¡å‹ç„¡æ³•æ»¿è¶³éœ€æ±‚æ™‚ä½¿ç”¨
   - å¯ç”¨æ–¼æ•¸æ“šæ¨™è¨»ã€å°æ¯”é©—è­‰ç­‰è¼”åŠ©ç”¨é€”

4. **å¯¦æ–½ç­–ç•¥**ï¼š
   - **ä¸»è¦è·¯ç·š**ï¼šä½¿ç”¨ TensorFlow è¨“ç·´åˆ†å±¤è­˜åˆ¥æ¨¡å‹ï¼ˆæœ¬æ¶æ§‹è¨­è¨ˆï¼‰
   - **è¼”åŠ©è·¯ç·š**ï¼šä¿ç•™ç¾æœ‰ç™¾åº¦ API ä½œç‚ºå°æ¯”å’Œå‚™é¸
   - **æ··åˆæ–¹æ¡ˆ**ï¼šè‡ªè¨“ç·´æ¨¡å‹ + API é©—è­‰ï¼Œæé«˜æº–ç¢ºç‡å’Œå¯é æ€§

## æŠ€è¡“åº«æ¸…å–®èˆ‡ Import èªå¥

### æ ¸å¿ƒä¾è³´åº«

#### 1. TensorFlow.jsï¼ˆæ·±åº¦å­¸ç¿’æ¡†æ¶ï¼‰

```typescript
// CPU ç‰ˆæœ¬ï¼ˆé»˜èªï¼‰
import * as tf from "@tensorflow/tfjs-node";

// GPU ç‰ˆæœ¬ï¼ˆéœ€è¦ CUDA ç’°å¢ƒï¼Œæ€§èƒ½æå‡ 5-10 å€ï¼‰
import * as tf from "@tensorflow/tfjs-node-gpu";
```

**å®‰è£**ï¼š

```bash
pnpm add @tensorflow/tfjs-node
# æˆ– GPU ç‰ˆæœ¬
pnpm add @tensorflow/tfjs-node-gpu
```

#### 2. åœ–åƒè™•ç†åº«

```typescript
// é«˜æ€§èƒ½åœ–åƒè™•ç†ï¼ˆå·²å®‰è£ï¼‰
import sharp from "sharp";

// å¯é¸ï¼šç´” JavaScript åœ–åƒè™•ç†ï¼ˆæ•¸æ“šå¢å¼·ï¼‰
import Jimp from "jimp";
```

**å®‰è£**ï¼š

```bash
# sharp å·²å®‰è£
pnpm add jimp
pnpm add -D @types/jimp
```

#### 3. æ•¸æ“šé›†ç®¡ç†

```typescript
// åœ–åƒæ•¸æ“šé›†åŠ è¼‰å’Œç®¡ç†
import { Dataset } from "image-dataset";
```

**å®‰è£**ï¼š

```bash
pnpm add image-dataset
```

#### 4. æ–‡ä»¶ç³»çµ±èˆ‡å·¥å…·

```typescript
// å¢å¼·çš„æ–‡ä»¶ç³»çµ±æ“ä½œ
import fs from "fs-extra";
import path from "path";
```

**å®‰è£**ï¼š

```bash
pnpm add fs-extra
pnpm add -D @types/fs-extra
```

#### 5. ç·©å­˜èˆ‡éšŠåˆ—ï¼ˆå¯é¸ï¼‰

```typescript
// çµæœç·©å­˜
import NodeCache from "node-cache";

// ç•°æ­¥éšŠåˆ—ç®¡ç†
import PQueue from "p-queue";
```

**å®‰è£**ï¼š

```bash
pnpm add node-cache p-queue
pnpm add -D @types/node-cache
```

#### 6. æ¨¡å‹è½‰æ›å·¥å…·ï¼ˆé–‹ç™¼ä¾è³´ï¼‰

```typescript
// ç”¨æ–¼å°‡ Python è¨“ç·´çš„æ¨¡å‹è½‰æ›ç‚º TensorFlow.js æ ¼å¼
// ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·ï¼Œç„¡éœ€ import
```

**å®‰è£**ï¼š

```bash
pnpm add -D @tensorflow/tfjs-converter
```

### å®Œæ•´ package.json ä¾è³´ç¤ºä¾‹

```json
{
  "dependencies": {
    "@tensorflow/tfjs-node": "^4.22.0",
    "@tensorflow/tfjs-node-gpu": "^4.22.0",
    "sharp": "^0.34.5",
    "jimp": "^0.22.10",
    "fs-extra": "^11.2.0",
    "image-dataset": "^1.0.0",
    "node-cache": "^5.1.2",
    "p-queue": "^8.0.1"
  },
  "devDependencies": {
    "@tensorflow/tfjs-converter": "^4.22.0",
    "@types/jimp": "^0.2.28",
    "@types/fs-extra": "^11.0.4",
    "@types/node-cache": "^4.2.5"
  }
}
```

### å…¸å‹æ–‡ä»¶çµæ§‹èˆ‡ Import

```typescript
// server/food-recognition/models/ModelLoader.ts
import * as tf from "@tensorflow/tfjs-node-gpu"; // æˆ– @tensorflow/tfjs-node
import path from "path";
import fs from "fs-extra";

// server/food-recognition/models/ImagePreprocessor.ts
import * as tf from "@tensorflow/tfjs-node";
import sharp from "sharp";

// server/food-recognition/models/RecognitionPipeline.ts
import * as tf from "@tensorflow/tfjs-node";
import { ModelLoader } from "./ModelLoader.js";
import { ImagePreprocessor } from "./ImagePreprocessor.js";
import { proxy } from "../../proxy.js";

// scripts/train/train-level1.ts
import * as tf from "@tensorflow/tfjs-node-gpu";
import { DataLoader } from "./data-loader.js";
import { buildFoodDetectionModel } from "./model-builder.js";
import path from "path";
```

### GPU ç’°å¢ƒè¦æ±‚

å¦‚æœä½¿ç”¨ `@tensorflow/tfjs-node-gpu`ï¼Œéœ€è¦ï¼š

1. **NVIDIA GPU**ï¼ˆæ”¯æŒ CUDAï¼‰
2. **CUDA Toolkit 11.2+**
3. **cuDNN 8.1+**
4. **Node.js 16+**

æª¢æŸ¥ GPU æ˜¯å¦å¯ç”¨ï¼š

```typescript
import * as tf from "@tensorflow/tfjs-node-gpu";

console.log("å¾Œç«¯:", tf.getBackend()); // æ‡‰è¼¸å‡º 'tensorflow'
console.log("GPU è¨­å‚™:", tf.engine().backend); // æ‡‰é¡¯ç¤º GPU ä¿¡æ¯
```

---

## æ¶æ§‹è¨­è¨ˆåŸå‰‡

1. **åˆ†å±¤è­˜åˆ¥**ï¼šæ¡ç”¨ç´šè¯åˆ†é¡å™¨ï¼Œé€å±¤ç´°åŒ–è­˜åˆ¥çµæœ
2. **é·ç§»å­¸ç¿’**ï¼šåˆ©ç”¨é è¨“ç·´æ¨¡å‹ï¼ˆå¦‚ ResNetã€EfficientNetï¼‰ä½œç‚ºç‰¹å¾µæå–å™¨
3. **æ¨¡å¡ŠåŒ–è¨­è¨ˆ**ï¼šæ¯å±¤æ¨¡å‹ç¨ç«‹è¨“ç·´å’Œéƒ¨ç½²ï¼Œä¾¿æ–¼ç¶­è­·å’Œå„ªåŒ–
4. **æ€§èƒ½å„ªåŒ–**ï¼šæ—©æœŸæ‹’çµ•éé£Ÿç‰©åœ–åƒï¼Œæ¸›å°‘è¨ˆç®—è³‡æºæ¶ˆè€—
5. **Node.js å„ªå…ˆ**ï¼šæ‰€æœ‰å¯¦ç¾åŸºæ–¼ Node.js/TypeScriptï¼Œç„¡éœ€ Python å¾®æœå‹™

---

## ä¸‰å±¤è­˜åˆ¥æ¶æ§‹

### ç¬¬ä¸€å±¤ï¼šé£Ÿç‰©æª¢æ¸¬ï¼ˆFood Detectionï¼‰

**ç›®æ¨™**ï¼šåˆ¤æ–·è¼¸å…¥åœ–åƒæ˜¯å¦åŒ…å«é£Ÿç‰©

**ä»»å‹™é¡å‹**ï¼šäºŒåˆ†é¡ï¼ˆFood / Non-Foodï¼‰

**è¨­è¨ˆè¦é»**ï¼š

- **è¼¸å…¥**ï¼šåŸå§‹åœ–åƒï¼ˆ224x224 æˆ– 256x256ï¼‰
- **è¼¸å‡º**ï¼š`{is_food: true/false, confidence: 0.0-1.0}`
- **æ¨¡å‹æ¶æ§‹**ï¼šè¼•é‡ç´š CNNï¼ˆå¦‚ MobileNetV2ï¼‰æˆ– ResNet18
- **æ•¸æ“šé›†è¦æ±‚**ï¼š
  - æ­£æ¨£æœ¬ï¼šå„ç¨®é£Ÿç‰©åœ–åƒï¼ˆ10,000+ å¼µï¼‰
  - è² æ¨£æœ¬ï¼šéé£Ÿç‰©åœ–åƒï¼ˆäººç‰©ã€é¢¨æ™¯ã€ç‰©å“ç­‰ï¼Œ10,000+ å¼µï¼‰
- **æ€§èƒ½ç›®æ¨™**ï¼šæº–ç¢ºç‡ > 95%ï¼Œæ¨ç†æ™‚é–“ < 50ms

**æ•¸æ“šé›†ä¾†æº**ï¼š

- Food-101 æ•¸æ“šé›†ï¼ˆæå–é£Ÿç‰©é¡åˆ¥ï¼‰
- ImageNet æ•¸æ“šé›†ï¼ˆæå–éé£Ÿç‰©é¡åˆ¥ï¼‰
- è‡ªå»ºæ•¸æ“šé›†ï¼ˆè£œå……æœ¬åœ°é£Ÿç‰©å ´æ™¯ï¼‰

**æ¨¡å‹é¸æ“‡å»ºè­°**ï¼š

```typescript
// ä½¿ç”¨ MobileNetV2 ä½œç‚ºåŸºç¤æ¨¡å‹ï¼ˆè¼•é‡ç´šï¼Œé©åˆå¿«é€Ÿæ¨ç†ï¼‰
// æ³¨æ„ï¼šTensorFlow.js éœ€è¦å…ˆè½‰æ›é è¨“ç·´æ¨¡å‹ï¼Œæˆ–å¾é ­æ§‹å»º

import * as tf from "@tensorflow/tfjs-node";

// æ–¹æ¡ˆ 1ï¼šåŠ è¼‰é è½‰æ›çš„ MobileNetV2 æ¨¡å‹
async function loadMobileNetV2() {
  // éœ€è¦å…ˆä½¿ç”¨ tfjs-converter å°‡ Keras MobileNetV2 è½‰æ›ç‚º TensorFlow.js æ ¼å¼
  const model = await tf.loadLayersModel(
    "https://tfhub.dev/google/tfjs-model/imagenet/mobilenet_v2_100_224/feature_vector/3/default/1"
  );
  return model;
}

// æ–¹æ¡ˆ 2ï¼šæ§‹å»ºé¡ä¼¼çš„è¼•é‡ç´šæ¨¡å‹
function buildLightweightModel(): tf.Sequential {
  return tf.sequential({
    layers: [
      tf.layers.conv2d({
        inputShape: [224, 224, 3],
        filters: 32,
        kernelSize: 3,
        activation: "relu",
        padding: "same",
      }),
      tf.layers.depthwiseConv2d({
        kernelSize: 3,
        activation: "relu",
        padding: "same",
      }),
      tf.layers.maxPooling2d({ poolSize: 2 }),
      // ... æ›´å¤šå±¤
      tf.layers.globalAveragePooling2d(),
      tf.layers.dense({ units: 1, activation: "sigmoid" }),
    ],
  });
}
```

---

### ç¬¬äºŒå±¤ï¼šåœ‹å®¶/åœ°å€è­˜åˆ¥ï¼ˆCuisine Classificationï¼‰

**ç›®æ¨™**ï¼šè­˜åˆ¥é£Ÿç‰©çš„åœ‹å®¶æˆ–åœ°å€ä¾†æº

**ä»»å‹™é¡å‹**ï¼šå¤šåˆ†é¡ï¼ˆç´„ 10-20 å€‹ä¸»è¦åœ‹å®¶/åœ°å€ï¼‰

**è¨­è¨ˆè¦é»**ï¼š

- **è¼¸å…¥**ï¼šé€šéç¬¬ä¸€å±¤é©—è­‰çš„é£Ÿç‰©åœ–åƒ
- **è¼¸å‡º**ï¼š`{country: "ä¸­åœ‹", confidence: 0.85, alternatives: [...]}`
- **åˆ†é¡é¡åˆ¥**ï¼ˆå»ºè­°ï¼‰ï¼š
  - ä¸­åœ‹ï¼ˆChineseï¼‰
  - æ—¥æœ¬ï¼ˆJapaneseï¼‰
  - éŸ“åœ‹ï¼ˆKoreanï¼‰
  - æ³°åœ‹ï¼ˆThaiï¼‰
  - å°åº¦ï¼ˆIndianï¼‰
  - æ„å¤§åˆ©ï¼ˆItalianï¼‰
  - æ³•åœ‹ï¼ˆFrenchï¼‰
  - å¢¨è¥¿å“¥ï¼ˆMexicanï¼‰
  - ç¾åœ‹ï¼ˆAmericanï¼‰
  - å…¶ä»–ï¼ˆOthersï¼‰
- **æ¨¡å‹æ¶æ§‹**ï¼šResNet50 æˆ– EfficientNet-B2
- **æ•¸æ“šé›†è¦æ±‚**ï¼šæ¯å€‹åœ‹å®¶/åœ°å€è‡³å°‘ 5,000 å¼µåœ–åƒ
- **æ€§èƒ½ç›®æ¨™**ï¼šTop-1 æº–ç¢ºç‡ > 80%ï¼ŒTop-3 æº–ç¢ºç‡ > 90%

**æ•¸æ“šé›†ä¾†æº**ï¼š

- **ChineseFoodNet**ï¼š18 è¬å¼µä¸­åœ‹èœå“åœ–åƒï¼Œ208 ç¨®èœå“
- **Food-101**ï¼š101 é¡é£Ÿç‰©ï¼Œå¯æ ¹æ“šåœ‹å®¶æ¨™è¨»
- **UECFOOD-256**ï¼š256 é¡æ—¥æœ¬é£Ÿç‰©
- **è‡ªå»ºæ•¸æ“šé›†**ï¼šæœ¬åœ°é¤å»³åœ–ç‰‡ã€ç”¨æˆ¶ä¸Šå‚³åœ–ç‰‡

**æ¨¡å‹é¸æ“‡å»ºè­°**ï¼š

```typescript
// ä½¿ç”¨ ResNet50 é€²è¡Œé·ç§»å­¸ç¿’
// éœ€è¦å…ˆè½‰æ›é è¨“ç·´æ¨¡å‹ï¼Œæˆ–æ§‹å»ºé¡ä¼¼æ¶æ§‹

import * as tf from "@tensorflow/tfjs-node";

// æ–¹æ¡ˆ 1ï¼šåŠ è¼‰é è½‰æ›çš„ ResNet50 æ¨¡å‹
async function loadResNet50() {
  // å¾ TensorFlow Hub æˆ–è½‰æ›å¾Œçš„æ¨¡å‹åŠ è¼‰
  const baseModel = await tf.loadLayersModel("path/to/resnet50/model.json");

  // æ·»åŠ è‡ªå®šç¾©åˆ†é¡é ­
  const x = baseModel.getLayer("global_average_pooling2d").output;
  const dense1 = tf.layers.dense({ units: 512, activation: "relu" }).apply(x);
  const dropout = tf.layers.dropout({ rate: 0.5 }).apply(dense1);
  const predictions = tf.layers
    .dense({
      units: 10, // 10 å€‹åœ‹å®¶
      activation: "softmax",
    })
    .apply(dropout);

  return tf.model({ inputs: baseModel.input, outputs: predictions });
}

// æ–¹æ¡ˆ 2ï¼šæ§‹å»º ResNet é¢¨æ ¼çš„æ¨¡å‹
function buildResNetStyleModel(numCountries: number): tf.Sequential {
  return tf.sequential({
    layers: [
      // ResNet é¢¨æ ¼çš„æ®˜å·®å¡Š
      tf.layers.conv2d({
        inputShape: [224, 224, 3],
        filters: 64,
        kernelSize: 7,
        strides: 2,
        activation: "relu",
        padding: "same",
      }),
      tf.layers.maxPooling2d({ poolSize: 3, strides: 2 }),
      // ... æ›´å¤šæ®˜å·®å¡Š
      tf.layers.globalAveragePooling2d(),
      tf.layers.dense({ units: 512, activation: "relu" }),
      tf.layers.dropout({ rate: 0.5 }),
      tf.layers.dense({ units: numCountries, activation: "softmax" }),
    ],
  });
}
```

---

### ç¬¬ä¸‰å±¤ï¼šç´°ç²’åº¦é£Ÿç‰©è­˜åˆ¥ï¼ˆFine-grained Food Classificationï¼‰

**ç›®æ¨™**ï¼šè­˜åˆ¥å…·é«”çš„é£Ÿç‰©ç¨®é¡

**ä»»å‹™é¡å‹**ï¼šç´°ç²’åº¦å¤šåˆ†é¡ï¼ˆ100-500 é¡ï¼‰

**è¨­è¨ˆè¦é»**ï¼š

- **è¼¸å…¥**ï¼šé€šéå‰å…©å±¤é©—è­‰çš„é£Ÿç‰©åœ–åƒ + åœ‹å®¶/åœ°å€ä¿¡æ¯
- **è¼¸å‡º**ï¼š`{food_name: "å®®ä¿é›ä¸", country: "ä¸­åœ‹", confidence: 0.92, calories: 280, ...}`
- **åˆ†é¡ç­–ç•¥**ï¼š
  - **æ–¹æ¡ˆ Aï¼ˆæ¨è–¦ï¼‰**ï¼šç‚ºæ¯å€‹åœ‹å®¶/åœ°å€è¨“ç·´å°ˆç”¨æ¨¡å‹
    - ä¸­åœ‹é£Ÿç‰©æ¨¡å‹ï¼šè­˜åˆ¥ 200+ ç¨®ä¸­åœ‹èœå“
    - æ—¥æœ¬é£Ÿç‰©æ¨¡å‹ï¼šè­˜åˆ¥ 100+ ç¨®æ—¥æœ¬æ–™ç†
    - å…¶ä»–åœ‹å®¶æ¨¡å‹ï¼šä¾æ•¸æ“šé‡æ±ºå®š
  - **æ–¹æ¡ˆ B**ï¼šå–®ä¸€å¤§å‹æ¨¡å‹ï¼ŒåŒ…å«æ‰€æœ‰é£Ÿç‰©é¡åˆ¥ï¼ˆ500+ é¡ï¼‰
- **æ¨¡å‹æ¶æ§‹**ï¼šResNet101ã€EfficientNet-B4 æˆ– Vision Transformer
- **æ•¸æ“šé›†è¦æ±‚**ï¼šæ¯ç¨®é£Ÿç‰©è‡³å°‘ 500 å¼µåœ–åƒ
- **æ€§èƒ½ç›®æ¨™**ï¼šTop-1 æº–ç¢ºç‡ > 75%ï¼ŒTop-5 æº–ç¢ºç‡ > 90%

**æ•¸æ“šé›†ä¾†æº**ï¼š

- **ChineseFoodNet**ï¼š208 ç¨®ä¸­åœ‹èœå“ï¼ˆ18 è¬å¼µåœ–åƒï¼‰
- **Food-101**ï¼š101 é¡åœ‹éš›é£Ÿç‰©
- **UECFOOD-256**ï¼š256 é¡æ—¥æœ¬é£Ÿç‰©
- **è‡ªå»ºæ•¸æ“šé›†**ï¼šæœ¬åœ°ç‰¹è‰²èœå“

**æ¨¡å‹é¸æ“‡å»ºè­°**ï¼š

```typescript
// é‡å°ä¸­åœ‹é£Ÿç‰©çš„å°ˆç”¨æ¨¡å‹
// ä½¿ç”¨ EfficientNet-B4 é¢¨æ ¼æˆ–é¡ä¼¼æ¶æ§‹

import * as tf from "@tensorflow/tfjs-node";

// æ–¹æ¡ˆ 1ï¼šåŠ è¼‰é è½‰æ›çš„ EfficientNet-B4 æ¨¡å‹
async function loadEfficientNetB4() {
  // éœ€è¦å…ˆè½‰æ›é è¨“ç·´æ¨¡å‹
  const baseModel = await tf.loadLayersModel(
    "path/to/efficientnet-b4/model.json"
  );

  // æ·»åŠ ç´°ç²’åº¦åˆ†é¡é ­
  const x = baseModel.getLayer("global_average_pooling2d").output;
  const dense1 = tf.layers.dense({ units: 1024, activation: "relu" }).apply(x);
  const bn1 = tf.layers.batchNormalization().apply(dense1);
  const dropout1 = tf.layers.dropout({ rate: 0.5 }).apply(bn1);
  const dense2 = tf.layers
    .dense({ units: 512, activation: "relu" })
    .apply(dropout1);
  const predictions = tf.layers
    .dense({
      units: 208, // 208 ç¨®ä¸­åœ‹èœå“
      activation: "softmax",
    })
    .apply(dense2);

  return tf.model({ inputs: baseModel.input, outputs: predictions });
}

// æ–¹æ¡ˆ 2ï¼šæ§‹å»º EfficientNet é¢¨æ ¼çš„æ¨¡å‹ï¼ˆå·²åœ¨ model-builder.ts ä¸­å¯¦ç¾ï¼‰
function buildEfficientNetStyleModel(numClasses: number): tf.Sequential {
  // åƒè¦‹ buildFineGrainedModel å‡½æ•¸å¯¦ç¾
  // ä½¿ç”¨æ·±åº¦å¯åˆ†é›¢å·ç©å’Œæ³¨æ„åŠ›æ©Ÿåˆ¶
}
```

---

## æ•¸æ“šé›†è¨­è¨ˆ

### æ•¸æ“šé›†çµæ§‹

```
food-recognition-dataset/
â”œâ”€â”€ level1-food-detection/
â”‚   â”œâ”€â”€ food/
â”‚   â”‚   â”œâ”€â”€ class1/
â”‚   â”‚   â”œâ”€â”€ class2/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ non-food/
â”‚       â”œâ”€â”€ people/
â”‚       â”œâ”€â”€ scenery/
â”‚       â””â”€â”€ objects/
â”‚
â”œâ”€â”€ level2-country-classification/
â”‚   â”œâ”€â”€ chinese/
â”‚   â”œâ”€â”€ japanese/
â”‚   â”œâ”€â”€ korean/
â”‚   â”œâ”€â”€ thai/
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ level3-fine-grained/
    â”œâ”€â”€ chinese/
    â”‚   â”œâ”€â”€ å®®ä¿é›ä¸/
    â”‚   â”œâ”€â”€ éº»å©†è±†è…/
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ japanese/
    â”‚   â”œâ”€â”€ å£½å¸/
    â”‚   â”œâ”€â”€ æ‹‰éºµ/
    â”‚   â””â”€â”€ ...
    â””â”€â”€ ...
```

### æ•¸æ“šé›†çµ±è¨ˆå»ºè­°

| å±¤ç´š   | é¡åˆ¥æ•¸  | æ¯é¡æ¨£æœ¬æ•¸ | ç¸½æ¨£æœ¬æ•¸ | è¨“ç·´/é©—è­‰/æ¸¬è©¦æ¯”ä¾‹ |
| ------ | ------- | ---------- | -------- | ------------------ |
| ç¬¬ä¸€å±¤ | 2       | 10,000+    | 20,000+  | 70/15/15           |
| ç¬¬äºŒå±¤ | 10-20   | 5,000+     | 50,000+  | 70/15/15           |
| ç¬¬ä¸‰å±¤ | 200-500 | 500+       | 100,000+ | 70/15/15           |

### æ•¸æ“šå¢å¼·ç­–ç•¥ï¼ˆNode.jsï¼‰

#### ä½¿ç”¨ sharp é€²è¡Œåœ–åƒå¢å¼·

```typescript
// scripts/train/augmentation.ts
import sharp from "sharp";

export class DataAugmentation {
  /**
   * æ‡‰ç”¨å®Œæ•´çš„æ•¸æ“šå¢å¼·ç®¡é“
   */
  async augmentImage(
    buffer: Buffer,
    options?: {
      rotation?: number; // æ—‹è½‰è§’åº¦ç¯„åœï¼ˆÂ±30åº¦ï¼‰
      flip?: boolean; // æ˜¯å¦æ°´å¹³ç¿»è½‰
      brightness?: [number, number]; // äº®åº¦ç¯„åœ [0.8, 1.2]
      zoom?: [number, number]; // ç¸®æ”¾ç¯„åœ [0.8, 1.2]
    }
  ): Promise<Buffer> {
    let augmented = buffer;

    // éš¨æ©Ÿæ—‹è½‰ï¼ˆÂ±30åº¦ï¼‰
    if (options?.rotation !== undefined) {
      const angle = (Math.random() - 0.5) * (options.rotation * 2);
      augmented = await sharp(augmented).rotate(angle).toBuffer();
    }

    // éš¨æ©Ÿæ°´å¹³ç¿»è½‰ï¼ˆ50% æ¦‚ç‡ï¼‰
    if (options?.flip && Math.random() > 0.5) {
      augmented = await sharp(augmented).flip().toBuffer();
    }

    // éš¨æ©Ÿäº®åº¦èª¿æ•´
    if (options?.brightness) {
      const [min, max] = options.brightness;
      const brightness = min + Math.random() * (max - min);
      augmented = await sharp(augmented).modulate({ brightness }).toBuffer();
    }

    // éš¨æ©Ÿç¸®æ”¾ï¼ˆé€šéè£å‰ªå’Œèª¿æ•´å¤§å°å¯¦ç¾ï¼‰
    if (options?.zoom) {
      const [minZoom, maxZoom] = options.zoom;
      const zoom = minZoom + Math.random() * (maxZoom - minZoom);
      const metadata = await sharp(augmented).metadata();
      const newWidth = Math.floor((metadata.width || 224) * zoom);
      const newHeight = Math.floor((metadata.height || 224) * zoom);
      augmented = await sharp(augmented)
        .resize(newWidth, newHeight)
        .resize(metadata.width || 224, metadata.height || 224, { fit: "fill" })
        .toBuffer();
    }

    return augmented;
  }

  /**
   * æ‰¹é‡å¢å¼·åœ–åƒ
   */
  async augmentBatch(
    images: Buffer[],
    augmentationFactor: number = 2
  ): Promise<Buffer[]> {
    const augmented: Buffer[] = [];

    for (const image of images) {
      // åŸå§‹åœ–åƒ
      augmented.push(image);

      // ç”Ÿæˆå¢å¼·ç‰ˆæœ¬
      for (let i = 0; i < augmentationFactor; i++) {
        const aug = await this.augmentImage(image, {
          rotation: 30,
          flip: true,
          brightness: [0.8, 1.2],
          zoom: [0.8, 1.2],
        });
        augmented.push(aug);
      }
    }

    return augmented;
  }
}
```

#### ä½¿ç”¨ TensorFlow.js é€²è¡Œå¼µé‡ç´šå¢å¼·

```typescript
import * as tf from '@tensorflow/tfjs-node';

/**
 * åœ¨å¼µé‡å±¤é¢é€²è¡Œæ•¸æ“šå¢å¼·ï¼ˆæ›´é«˜æ•ˆï¼‰
 */
export function augmentTensor(imageTensor: tf.Tensor4D): tf.Tensor4D {
  let augmented = imageTensor;

  // éš¨æ©Ÿæ°´å¹³ç¿»è½‰
  if (Math.random() > 0.5) {
    augmented = tf.image.flipLeftRight(augmented);
  }

  // éš¨æ©Ÿæ—‹è½‰ï¼ˆé€šéè½‰ç½®å’Œç¿»è½‰å¯¦ç¾ï¼‰
  if (Math.random() > 0.5) {
    const k = Math.floor(Math.random() * 4);
    augmented = tf.image.rot90(augmented, k);
  }

  // éš¨æ©Ÿäº®åº¦èª¿æ•´
  if (Math.random() > 0.5) {
    const delta = (Math.random() - 0.5) * 0.2; // Â±0.1
    augmented = tf.image.adjustBrightness(augmented, delta);
  }

  // éš¨æ©Ÿå°æ¯”åº¦èª¿æ•´
  if (Math.random() > 0.5) {
    const factor = 0.8 + Math.random() * 0.4; // 0.8 åˆ° 1.2
    augmented = tf.image.adjustContrast(augmented, factor);
  }

  return augmented;
}

/**
 * åœ¨æ•¸æ“šç®¡é“ä¸­æ‡‰ç”¨å¢å¼·
 */
export function createAugmentedDataset(
  baseDataset: tf.data.Dataset<{ xs: tf.Tensor4D; ys: tf.Tensor }
): tf.data.Dataset<{ xs: tf.Tensor4D; ys: tf.Tensor }> {
  return baseDataset.map((item) => ({
    xs: augmentTensor(item.xs),
    ys: item.ys,
  }));
}
```

#### å®Œæ•´çš„æ•¸æ“šå¢å¼·é…ç½®

```typescript
// è¨“ç·´æ™‚çš„æ•¸æ“šå¢å¼·é…ç½®
const augmentationConfig = {
  rotation: 30, // æ—‹è½‰ Â±30 åº¦
  flip: true, // æ°´å¹³ç¿»è½‰
  brightness: [0.8, 1.2], // äº®åº¦èª¿æ•´ç¯„åœ
  zoom: [0.8, 1.2], // ç¸®æ”¾ç¯„åœ
  contrast: [0.8, 1.2], // å°æ¯”åº¦ç¯„åœ
  saturation: [0.8, 1.2], // é£½å’Œåº¦ç¯„åœ
};

// åœ¨æ•¸æ“šåŠ è¼‰æ™‚æ‡‰ç”¨
const augmentedDataset = createAugmentedDataset(trainDataset);
```

---

## æ¨¡å‹è¨“ç·´æµç¨‹

### è¨“ç·´ç’°å¢ƒè¨­ç½®

#### ä½¿ç”¨ GPU è¨“ç·´ï¼ˆæ¨è–¦ï¼‰

```bash
# å®‰è£ GPU ç‰ˆæœ¬
pnpm add @tensorflow/tfjs-node-gpu

# æª¢æŸ¥ GPU æ˜¯å¦å¯ç”¨
node -e "require('@tensorflow/tfjs-node-gpu'); console.log('GPU å¯ç”¨')"
```

#### è¨“ç·´è…³æœ¬çµæ§‹

```
scripts/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ train-level1.ts      # ç¬¬ä¸€å±¤æ¨¡å‹è¨“ç·´
â”‚   â”œâ”€â”€ train-level2.ts      # ç¬¬äºŒå±¤æ¨¡å‹è¨“ç·´
â”‚   â”œâ”€â”€ train-level3.ts      # ç¬¬ä¸‰å±¤æ¨¡å‹è¨“ç·´
â”‚   â”œâ”€â”€ data-loader.ts       # æ•¸æ“šåŠ è¼‰å·¥å…·
â”‚   â””â”€â”€ model-builder.ts     # æ¨¡å‹æ§‹å»ºå·¥å…·
```

### éšæ®µ 1ï¼šç¬¬ä¸€å±¤æ¨¡å‹è¨“ç·´ï¼ˆNode.js/TypeScriptï¼‰

```typescript
// scripts/train/train-level1.ts
import * as tf from "@tensorflow/tfjs-node-gpu"; // æˆ– @tensorflow/tfjs-node
import { DataLoader } from "./data-loader.js";
import { buildFoodDetectionModel } from "./model-builder.js";
import path from "path";

async function trainLevel1() {
  console.log("ğŸš€ é–‹å§‹è¨“ç·´ç¬¬ä¸€å±¤æ¨¡å‹ï¼ˆé£Ÿç‰©æª¢æ¸¬ï¼‰...");

  // 1. æº–å‚™æ•¸æ“š
  const dataLoader = new DataLoader();
  const { trainDataset, valDataset } = await dataLoader.loadFoodDetectionData({
    dataPath: "./data/level1-food-detection",
    batchSize: 32,
    imageSize: [224, 224],
  });

  // 2. æ§‹å»ºæ¨¡å‹
  const model = buildFoodDetectionModel();
  console.log("âœ… æ¨¡å‹æ§‹å»ºå®Œæˆ");

  // 3. ç·¨è­¯æ¨¡å‹
  model.compile({
    optimizer: tf.train.adam(0.001),
    loss: "binaryCrossentropy",
    metrics: ["accuracy", "precision", "recall"],
  });

  // 4. è¨“ç·´æ¨¡å‹
  const history = await model.fitDataset(trainDataset, {
    epochs: 20,
    validationData: valDataset,
    callbacks: {
      onEpochEnd: (epoch, logs) => {
        console.log(
          `Epoch ${epoch + 1}: loss=${logs?.loss?.toFixed(
            4
          )}, acc=${logs?.acc?.toFixed(4)}`
        );
      },
    },
  });

  // 5. ä¿å­˜æ¨¡å‹
  const savePath = path.resolve("./models/level1");
  await model.save(`file://${savePath}`);
  console.log(`âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: ${savePath}`);

  return model;
}

// åŸ·è¡Œè¨“ç·´
trainLevel1().catch(console.error);
```

```typescript
// scripts/train/model-builder.ts
import * as tf from "@tensorflow/tfjs-node";

/**
 * æ§‹å»ºç¬¬ä¸€å±¤æ¨¡å‹ï¼ˆé£Ÿç‰©æª¢æ¸¬ï¼‰
 */
export function buildFoodDetectionModel(): tf.Sequential {
  // ä½¿ç”¨ MobileNetV2 ä½œç‚ºåŸºç¤æ¨¡å‹ï¼ˆé·ç§»å­¸ç¿’ï¼‰
  const baseModel = tf.sequential({
    layers: [
      // é€™è£¡éœ€è¦åŠ è¼‰é è¨“ç·´çš„ MobileNetV2 æ¬Šé‡
      // æˆ–ä½¿ç”¨ tf.loadLayersModel() åŠ è¼‰é è¨“ç·´æ¨¡å‹
      tf.layers.dense({ units: 1, activation: "sigmoid" }),
    ],
  });

  // æˆ–è€…æ§‹å»ºè‡ªå®šç¾©æ¨¡å‹
  const model = tf.sequential({
    layers: [
      tf.layers.conv2d({
        inputShape: [224, 224, 3],
        filters: 32,
        kernelSize: 3,
        activation: "relu",
      }),
      tf.layers.maxPooling2d({ poolSize: 2 }),
      tf.layers.conv2d({ filters: 64, kernelSize: 3, activation: "relu" }),
      tf.layers.maxPooling2d({ poolSize: 2 }),
      tf.layers.conv2d({ filters: 128, kernelSize: 3, activation: "relu" }),
      tf.layers.maxPooling2d({ poolSize: 2 }),
      tf.layers.flatten(),
      tf.layers.dense({ units: 512, activation: "relu" }),
      tf.layers.dropout({ rate: 0.5 }),
      tf.layers.dense({ units: 1, activation: "sigmoid" }),
    ],
  });

  return model;
}

/**
 * æ§‹å»ºç¬¬äºŒå±¤æ¨¡å‹ï¼ˆåœ‹å®¶åˆ†é¡ï¼‰
 */
export function buildCountryClassificationModel(
  numCountries: number
): tf.Sequential {
  const model = tf.sequential({
    layers: [
      tf.layers.conv2d({
        inputShape: [224, 224, 3],
        filters: 64,
        kernelSize: 3,
        activation: "relu",
      }),
      tf.layers.maxPooling2d({ poolSize: 2 }),
      tf.layers.conv2d({ filters: 128, kernelSize: 3, activation: "relu" }),
      tf.layers.maxPooling2d({ poolSize: 2 }),
      tf.layers.conv2d({ filters: 256, kernelSize: 3, activation: "relu" }),
      tf.layers.maxPooling2d({ poolSize: 2 }),
      tf.layers.flatten(),
      tf.layers.dense({ units: 512, activation: "relu" }),
      tf.layers.dropout({ rate: 0.5 }),
      tf.layers.dense({ units: numCountries, activation: "softmax" }),
    ],
  });

  return model;
}
```

```typescript
// scripts/train/data-loader.ts
import * as tf from "@tensorflow/tfjs-node";
import { Dataset } from "image-dataset";
import sharp from "sharp";
import fs from "fs-extra";
import path from "path";

export class DataLoader {
  /**
   * åŠ è¼‰é£Ÿç‰©æª¢æ¸¬æ•¸æ“šé›†
   */
  async loadFoodDetectionData(options: {
    dataPath: string;
    batchSize: number;
    imageSize: [number, number];
  }): Promise<{ trainDataset: tf.data.Dataset; valDataset: tf.data.Dataset }> {
    const { dataPath, batchSize, imageSize } = options;

    // ä½¿ç”¨ image-dataset åŠ è¼‰æ•¸æ“š
    const dataset = new Dataset({
      path: dataPath,
      imageSize,
    });

    // åŠƒåˆ†è¨“ç·´é›†å’Œé©—è­‰é›†
    const trainData = await this.loadImagesFromDirectory(
      path.join(dataPath, "train"),
      imageSize
    );
    const valData = await this.loadImagesFromDirectory(
      path.join(dataPath, "val"),
      imageSize
    );

    // è½‰æ›ç‚º TensorFlow.js Dataset
    const trainDataset = tf.data
      .array(trainData)
      .map((item: any) => ({
        xs: item.image,
        ys: item.label,
      }))
      .batch(batchSize);

    const valDataset = tf.data
      .array(valData)
      .map((item: any) => ({
        xs: item.image,
        ys: item.label,
      }))
      .batch(batchSize);

    return { trainDataset, valDataset };
  }

  /**
   * å¾ç›®éŒ„åŠ è¼‰åœ–åƒ
   */
  private async loadImagesFromDirectory(
    dirPath: string,
    imageSize: [number, number]
  ): Promise<any[]> {
    const files = await fs.readdir(dirPath);
    const images = [];

    for (const file of files) {
      if (!/\.(jpg|jpeg|png)$/i.test(file)) continue;

      const filePath = path.join(dirPath, file);
      const buffer = await fs.readFile(filePath);
      const resized = await sharp(buffer)
        .resize(imageSize[0], imageSize[1])
        .raw()
        .toBuffer();

      // è½‰æ›ç‚ºå¼µé‡
      const tensor = tf.node.decodeImage(buffer);
      const normalized = tensor.div(255.0);

      images.push({
        image: normalized,
        label: this.getLabelFromPath(filePath),
      });
    }

    return images;
  }

  private getLabelFromPath(filePath: string): number {
    // æ ¹æ“šæ–‡ä»¶è·¯å¾‘ç¢ºå®šæ¨™ç±¤
    // food/ -> 1, non-food/ -> 0
    return filePath.includes("food") ? 1 : 0;
  }
}
```

### éšæ®µ 2ï¼šç¬¬äºŒå±¤æ¨¡å‹è¨“ç·´

```typescript
// scripts/train/train-level2.ts
import * as tf from "@tensorflow/tfjs-node-gpu";
import { DataLoader } from "./data-loader.js";
import { buildCountryClassificationModel } from "./model-builder.js";

async function trainLevel2() {
  console.log("ğŸš€ é–‹å§‹è¨“ç·´ç¬¬äºŒå±¤æ¨¡å‹ï¼ˆåœ‹å®¶åˆ†é¡ï¼‰...");

  const dataLoader = new DataLoader();
  const { trainDataset, valDataset } = await dataLoader.loadCountryData({
    dataPath: "./data/level2-country-classification",
    batchSize: 32,
    imageSize: [224, 224],
  });

  const model = buildCountryClassificationModel(10); // 10 å€‹åœ‹å®¶

  model.compile({
    optimizer: tf.train.adam(0.001),
    loss: "categoricalCrossentropy",
    metrics: ["accuracy"],
  });

  await model.fitDataset(trainDataset, {
    epochs: 30,
    validationData: valDataset,
  });

  await model.save("file://./models/level2");
  console.log("âœ… ç¬¬äºŒå±¤æ¨¡å‹è¨“ç·´å®Œæˆ");
}
```

### éšæ®µ 3ï¼šç¬¬ä¸‰å±¤æ¨¡å‹è¨“ç·´ï¼ˆæŒ‰åœ‹å®¶åˆ†åˆ¥è¨“ç·´ï¼‰

```typescript
// scripts/train/train-level3.ts
import * as tf from "@tensorflow/tfjs-node-gpu";
import { DataLoader } from "./data-loader.js";
import { buildFineGrainedModel } from "./model-builder.js";

const countries = ["chinese", "japanese", "korean", "thai", "indian"];

async function trainLevel3() {
  for (const country of countries) {
    console.log(`ğŸš€ é–‹å§‹è¨“ç·´ ${country} åœ‹å®¶æ¨¡å‹...`);

    const dataLoader = new DataLoader();
    const { trainDataset, valDataset } = await dataLoader.loadFineGrainedData({
      dataPath: `./data/level3-fine-grained/${country}`,
      batchSize: 16,
      imageSize: [380, 380],
    });

    // ç²å–è©²åœ‹å®¶çš„é£Ÿç‰©é¡åˆ¥æ•¸é‡
    const numClasses = await dataLoader.getNumClasses(country);
    const model = buildFineGrainedModel(numClasses);

    model.compile({
      optimizer: tf.train.adam(0.0001),
      loss: "categoricalCrossentropy",
      metrics: ["accuracy", "top5Accuracy"],
    });

    await model.fitDataset(trainDataset, {
      epochs: 50,
      validationData: valDataset,
    });

    await model.save(`file://./models/level3/${country}`);
    console.log(`âœ… ${country} åœ‹å®¶æ¨¡å‹è¨“ç·´å®Œæˆ`);
  }
}
```

---

## æ¨ç†æµç¨‹è¨­è¨ˆ

### ç´šè¯æ¨ç†æµç¨‹ï¼ˆNode.js/TypeScriptï¼‰

å®Œæ•´çš„æ¨ç†æµç¨‹å·²åœ¨ã€Œéƒ¨ç½²æ¶æ§‹ã€éƒ¨åˆ†çš„ `RecognitionPipeline.ts` ä¸­å¯¦ç¾ã€‚ä»¥ä¸‹æ˜¯é—œéµè¦é»ï¼š

#### æ¨ç†æµç¨‹åœ–

```
è¼¸å…¥åœ–åƒ (Buffer)
    â†“
åœ–åƒé è™•ç† (sharp + tf.node.decodeImage)
    â†“
ç¬¬ä¸€å±¤ï¼šé£Ÿç‰©æª¢æ¸¬ (MobileNetV2)
    â”œâ”€ éé£Ÿç‰© â†’ è¿”å› {is_food: false}
    â””â”€ æ˜¯é£Ÿç‰© â†’ ç¹¼çºŒ
    â†“
ç¬¬äºŒå±¤ï¼šåœ‹å®¶åˆ†é¡ (ResNet50)
    â”œâ”€ ç½®ä¿¡åº¦ < 0.3 â†’ è¿”å› {country: 'unknown'}
    â””â”€ ç½®ä¿¡åº¦ â‰¥ 0.3 â†’ ç¹¼çºŒ
    â†“
ç¬¬ä¸‰å±¤ï¼šç´°ç²’åº¦è­˜åˆ¥ (EfficientNet-B4, æŒ‰åœ‹å®¶)
    â†“
æŸ¥è©¢æ•¸æ“šåº«ç²å–é£Ÿç‰©ä¿¡æ¯
    â†“
è¿”å›å®Œæ•´è­˜åˆ¥çµæœ
```

#### é—œéµå¯¦ç¾ç´°ç¯€

```typescript
// server/food-recognition/models/RecognitionPipeline.ts (é—œéµéƒ¨åˆ†)

async recognizeFoodImage(imageBuffer: Buffer): Promise<RecognitionResult> {
  // 1. é è™•ç†åœ–åƒ
  const imageTensor = await this.preprocessor.preprocessImage(imageBuffer, [224, 224]);

  // 2. ç¬¬ä¸€å±¤ï¼šé£Ÿç‰©æª¢æ¸¬
  const level1Model = this.modelLoader.getLevel1Model();
  const level1Prediction = level1Model.predict(imageTensor) as tf.Tensor;
  const foodProbability = (await level1Prediction.data())[0];

  // æ—©æœŸæ‹’çµ•ï¼šéé£Ÿç‰©åœ–åƒç›´æ¥è¿”å›
  if (foodProbability <= 0.5) {
    imageTensor.dispose();
    level1Prediction.dispose();
    return { is_food: false, confidence: 1 - foodProbability };
  }

  // 3. ç¬¬äºŒå±¤ï¼šåœ‹å®¶è­˜åˆ¥
  const level2Model = this.modelLoader.getLevel2Model();
  const level2Prediction = level2Model.predict(imageTensor) as tf.Tensor;
  // ... è™•ç†åœ‹å®¶åˆ†é¡çµæœ

  // 4. ç¬¬ä¸‰å±¤ï¼šç´°ç²’åº¦è­˜åˆ¥
  const countryModel = this.modelLoader.getCountryModel(country);
  const level3Prediction = countryModel.predict(imageTensor) as tf.Tensor;
  // ... è™•ç†é£Ÿç‰©åˆ†é¡çµæœ

  // 5. æ¸…ç†å¼µé‡ï¼ˆé‡è¦ï¼šé¿å…å…§å­˜æ´©æ¼ï¼‰
  imageTensor.dispose();
  level1Prediction.dispose();
  level2Prediction.dispose();
  level3Prediction.dispose();

  return result;
}
```

### æ€§èƒ½å„ªåŒ–ç­–ç•¥

#### 1. æ—©æœŸæ‹’çµ•ï¼ˆEarly Rejectionï¼‰

ç¬¬ä¸€å±¤æ¨¡å‹å¿«é€Ÿéæ¿¾éé£Ÿç‰©åœ–åƒï¼Œæ¸›å°‘å¾ŒçºŒè¨ˆç®—ï¼š

```typescript
// å¦‚æœç¬¬ä¸€å±¤ç½®ä¿¡åº¦ä½æ–¼é–¾å€¼ï¼Œç«‹å³è¿”å›
if (foodProbability < 0.5) {
  return { is_food: false, message: "æœªæª¢æ¸¬åˆ°é£Ÿç‰©" };
}
```

#### 2. æ¨¡å‹é‡åŒ–ï¼ˆModel Quantizationï¼‰

ä½¿ç”¨ TensorFlow.js çš„é‡åŒ–å·¥å…·æ¸›å°‘æ¨¡å‹å¤§å°å’Œæ¨ç†æ™‚é–“ï¼š

```typescript
// scripts/quantize-model.ts
import * as tf from "@tensorflow/tfjs-node";

async function quantizeModel(modelPath: string, outputPath: string) {
  // åŠ è¼‰æ¨¡å‹
  const model = await tf.loadLayersModel(`file://${modelPath}/model.json`);

  // é‡åŒ–æ¨¡å‹ï¼ˆINT8ï¼‰
  // æ³¨æ„ï¼šTensorFlow.js çš„é‡åŒ–éœ€è¦åœ¨è¨“ç·´æ™‚è¨­ç½®ï¼Œæˆ–ä½¿ç”¨è½‰æ›å·¥å…·
  // å¯ä»¥ä½¿ç”¨ tfjs-converter é€²è¡Œé‡åŒ–è½‰æ›

  // ä¿å­˜é‡åŒ–æ¨¡å‹
  await model.save(`file://${outputPath}`);
}
```

#### 3. æ‰¹é‡æ¨ç†ï¼ˆBatch Inferenceï¼‰

å°å¤šå¼µåœ–ç‰‡é€²è¡Œæ‰¹é‡è™•ç†ï¼Œæé«˜ GPU åˆ©ç”¨ç‡ï¼š

```typescript
async recognizeBatch(imageBuffers: Buffer[]): Promise<RecognitionResult[]> {
  // æ‰¹é‡é è™•ç†
  const imageTensors = await this.preprocessor.preprocessBatch(
    imageBuffers,
    [224, 224]
  );

  // æ‰¹é‡æ¨ç†
  const predictions = await this.model.predict(imageTensors);

  // è™•ç†çµæœ
  const results = await this.processBatchResults(predictions);

  // æ¸…ç†
  imageTensors.dispose();
  predictions.dispose();

  return results;
}
```

#### 4. ç·©å­˜æ©Ÿåˆ¶ï¼ˆCachingï¼‰

å°å¸¸è¦‹é£Ÿç‰©é€²è¡Œçµæœç·©å­˜ï¼š

```typescript
import NodeCache from "node-cache";

export class RecognitionCache {
  private cache: NodeCache;

  constructor() {
    this.cache = new NodeCache({ stdTTL: 3600 }); // 1 å°æ™‚éæœŸ
  }

  async getCachedResult(imageHash: string): Promise<RecognitionResult | null> {
    return this.cache.get(imageHash) || null;
  }

  setCachedResult(imageHash: string, result: RecognitionResult): void {
    this.cache.set(imageHash, result);
  }

  // ä½¿ç”¨åœ–åƒå“ˆå¸Œä½œç‚ºç·©å­˜éµ
  private async hashImage(buffer: Buffer): Promise<string> {
    const crypto = await import("crypto");
    return crypto.createHash("sha256").update(buffer).digest("hex");
  }
}
```

#### 5. GPU åŠ é€Ÿ

ä½¿ç”¨ `@tensorflow/tfjs-node-gpu` é€²è¡Œ GPU æ¨ç†ï¼š

```typescript
// åœ¨æ¨¡å‹åŠ è¼‰æ™‚ä½¿ç”¨ GPU ç‰ˆæœ¬
import * as tf from "@tensorflow/tfjs-node-gpu";

// æª¢æŸ¥ GPU æ˜¯å¦å¯ç”¨
console.log("GPU å¾Œç«¯:", tf.getBackend());
// è¼¸å‡º: 'tensorflow' (GPU) æˆ– 'cpu' (CPU)
```

#### 6. ç•°æ­¥æ¨ç†éšŠåˆ—

ä½¿ç”¨éšŠåˆ—è™•ç†å¤§é‡ä¸¦ç™¼è«‹æ±‚ï¼š

```typescript
import PQueue from "p-queue";

export class RecognitionQueue {
  private queue: PQueue;

  constructor() {
    // é™åˆ¶ä¸¦ç™¼æ•¸ï¼Œé¿å… GPU å…§å­˜æº¢å‡º
    this.queue = new PQueue({ concurrency: 2 });
  }

  async add(imageBuffer: Buffer): Promise<RecognitionResult> {
    return this.queue.add(() =>
      this.recognitionPipeline.recognizeFoodImage(imageBuffer)
    );
  }
}
```

### æ€§èƒ½ç›£æ§

```typescript
import { performance } from 'perf_hooks';

async recognizeWithMetrics(imageBuffer: Buffer): Promise<RecognitionResult & { metrics: any }> {
  const start = performance.now();

  // ç¬¬ä¸€å±¤æ¨ç†æ™‚é–“
  const level1Start = performance.now();
  const level1Result = await this.level1Inference(imageBuffer);
  const level1Time = performance.now() - level1Start;

  // ç¬¬äºŒå±¤æ¨ç†æ™‚é–“
  const level2Start = performance.now();
  const level2Result = await this.level2Inference(imageBuffer);
  const level2Time = performance.now() - level2Start;

  // ç¬¬ä¸‰å±¤æ¨ç†æ™‚é–“
  const level3Start = performance.now();
  const level3Result = await this.level3Inference(imageBuffer);
  const level3Time = performance.now() - level3Start;

  const totalTime = performance.now() - start;

  return {
    ...level3Result,
    metrics: {
      total_time_ms: totalTime,
      level1_time_ms: level1Time,
      level2_time_ms: level2Time,
      level3_time_ms: level3Time,
    },
  };
}
```

---

## æŠ€è¡“æ£§é¸æ“‡

### æ ¸å¿ƒæŠ€è¡“è·¯ç·šï¼šNode.js + TensorFlow.js

æœ¬é …ç›®æ¡ç”¨ **Node.js ç”Ÿæ…‹ç³»çµ±**ï¼Œä½¿ç”¨ **TensorFlow.js for Node.js** é€²è¡Œæ¨¡å‹è¨“ç·´å’Œæ¨ç†ï¼Œæ”¯æŒ GPU åŠ é€Ÿã€‚

### æ·±åº¦å­¸ç¿’æ¡†æ¶ï¼ˆNode.jsï¼‰

#### ä¸»è¦æ¡†æ¶

- **`@tensorflow/tfjs-node`**ï¼šTensorFlow.js çš„ Node.js ç‰ˆæœ¬ï¼Œæ”¯æŒ CPU æ¨ç†
- **`@tensorflow/tfjs-node-gpu`**ï¼šTensorFlow.js çš„ Node.js GPU ç‰ˆæœ¬ï¼ˆéœ€è¦ CUDA å’Œ cuDNNï¼‰
  - **GPU è¦æ±‚**ï¼šNVIDIA GPU + CUDA 11.2+ + cuDNN 8.1+
  - **æ€§èƒ½æå‡**ï¼šç›¸æ¯” CPU ç‰ˆæœ¬ï¼Œæ¨ç†é€Ÿåº¦å¯æå‡ 5-10 å€

#### æ¨¡å‹æ ¼å¼èˆ‡è½‰æ›

- **æ¨¡å‹æ ¼å¼**ï¼šTensorFlow.js æ¨¡å‹ï¼ˆ`.json` + `.bin` æ–‡ä»¶ï¼‰æˆ– TensorFlow SavedModel
- **æ¨¡å‹è½‰æ›**ï¼šä½¿ç”¨ `tfjs-converter` å°‡ Python è¨“ç·´çš„ Keras æ¨¡å‹è½‰æ›ç‚º TensorFlow.js æ ¼å¼
- **æ¨¡å‹åŠ è¼‰**ï¼šä½¿ç”¨ `tf.loadLayersModel()` æˆ– `tf.loadGraphModel()` åŠ è¼‰æ¨¡å‹

#### å®‰è£ä¾è³´

```bash
# CPU ç‰ˆæœ¬ï¼ˆé»˜èªï¼‰
pnpm add @tensorflow/tfjs-node

# GPU ç‰ˆæœ¬ï¼ˆéœ€è¦ CUDA ç’°å¢ƒï¼‰
pnpm add @tensorflow/tfjs-node-gpu

# æ¨¡å‹è½‰æ›å·¥å…·ï¼ˆç”¨æ–¼å°‡ Python è¨“ç·´çš„æ¨¡å‹è½‰æ›ç‚º TensorFlow.jsï¼‰
pnpm add -D @tensorflow/tfjs-converter
```

### åœ–åƒè™•ç†åº«ï¼ˆNode.jsï¼‰

#### æ ¸å¿ƒåœ–åƒè™•ç†

- **`sharp`**ï¼šé«˜æ€§èƒ½åœ–åƒè™•ç†åº«ï¼ˆå·²å®‰è£ï¼‰
  - åœ–åƒç¸®æ”¾ã€è£å‰ªã€æ ¼å¼è½‰æ›
  - æ”¯æŒ JPEGã€PNGã€WebP ç­‰æ ¼å¼
  - æ€§èƒ½å„ªç•°ï¼Œä½¿ç”¨ libvips

#### åœ–åƒæ•¸æ“šå¢å¼·ï¼ˆå¯é¸ï¼‰

- **`jimp`**ï¼šç´” JavaScript åœ–åƒè™•ç†åº«
  - æ—‹è½‰ã€ç¿»è½‰ã€äº®åº¦èª¿æ•´ç­‰
  - é©åˆæ•¸æ“šå¢å¼·æ“ä½œ

#### å®‰è£ä¾è³´

```bash
# sharp å·²å®‰è£ï¼Œå¦‚éœ€æ•¸æ“šå¢å¼·å¯æ·»åŠ 
pnpm add jimp
pnpm add -D @types/jimp
```

### æ•¸æ“šè™•ç†èˆ‡å·¥å…·åº«

#### æ•¸æ“šé›†ç®¡ç†

- **`image-dataset`**ï¼šåœ–åƒæ•¸æ“šé›†ç®¡ç†å·¥å…·ï¼ˆå·²å®‰è£ï¼‰
  - æ•¸æ“šé›†åŠ è¼‰ã€é è™•ç†ã€æ‰¹è™•ç†
  - æ”¯æŒæ•¸æ“šå¢å¼·ç®¡é“

#### æ–‡ä»¶ç³»çµ±èˆ‡è·¯å¾‘

- **`fs-extra`**ï¼šå¢å¼·çš„æ–‡ä»¶ç³»çµ±æ“ä½œ
  - éæ­¸ç›®éŒ„æ“ä½œã€æ–‡ä»¶è¤‡è£½ç­‰

#### å®‰è£ä¾è³´

```bash
pnpm add fs-extra
pnpm add -D @types/fs-extra
```

### é è¨“ç·´æ¨¡å‹é¸æ“‡

| å±¤ç´š   | æ¨è–¦æ¨¡å‹        | è¼¸å…¥å°ºå¯¸ | åƒæ•¸é‡ | æ¨ç†æ™‚é–“ï¼ˆCPUï¼‰ | æ¨ç†æ™‚é–“ï¼ˆGPUï¼‰ |
| ------ | --------------- | -------- | ------ | --------------- | --------------- |
| ç¬¬ä¸€å±¤ | MobileNetV2     | 224x224  | 3.4M   | ~20ms           | ~5ms            |
| ç¬¬äºŒå±¤ | ResNet50        | 224x224  | 25.6M  | ~80ms           | ~15ms           |
| ç¬¬ä¸‰å±¤ | EfficientNet-B4 | 380x380  | 19M    | ~150ms          | ~30ms           |

### é–‹ç™¼èˆ‡èª¿è©¦å·¥å…·

- **æ•¸æ“šå¯è¦–åŒ–**ï¼š`chart.js` æˆ– `plotly.js`ï¼ˆç”¨æ–¼è¨“ç·´æ›²ç·šå¯è¦–åŒ–ï¼‰
- **æ—¥èªŒè¨˜éŒ„**ï¼š`winston` æˆ– `pino`ï¼ˆçµæ§‹åŒ–æ—¥èªŒï¼‰
- **æ€§èƒ½ç›£æ§**ï¼šNode.js å…§å»º `perf_hooks` æˆ– `clinic.js`
- **æ¨¡å‹ç®¡ç†**ï¼šè‡ªå®šç¾©ç‰ˆæœ¬ç®¡ç†ç³»çµ±ï¼ˆåŸºæ–¼æ–‡ä»¶ç³»çµ±æˆ–æ•¸æ“šåº«ï¼‰

### å®Œæ•´ä¾è³´åˆ—è¡¨

```json
{
  "dependencies": {
    "@tensorflow/tfjs-node": "^4.22.0",
    "@tensorflow/tfjs-node-gpu": "^4.22.0", // å¯é¸ï¼Œéœ€è¦ GPU
    "sharp": "^0.34.5", // å·²å®‰è£
    "jimp": "^0.22.10", // å¯é¸ï¼Œæ•¸æ“šå¢å¼·
    "fs-extra": "^11.2.0",
    "image-dataset": "^1.0.0" // å·²å®‰è£
  },
  "devDependencies": {
    "@tensorflow/tfjs-converter": "^4.22.0", // æ¨¡å‹è½‰æ›å·¥å…·
    "@types/jimp": "^0.2.28",
    "@types/fs-extra": "^11.0.4"
  }
}
```

---

## æ•¸æ“šåº«è¨­è¨ˆ

### é£Ÿç‰©ä¿¡æ¯è¡¨ï¼ˆfood_infoï¼‰

```sql
CREATE TABLE food_info (
    id INTEGER PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    name_en VARCHAR(255),
    country VARCHAR(50) NOT NULL,
    category VARCHAR(100),           -- èœå“é¡åˆ¥ï¼ˆä¸»èœã€æ¹¯å“ã€ç”œå“ç­‰ï¼‰
    calories INTEGER,                -- å¡è·¯é‡Œï¼ˆæ¯100gï¼‰
    protein DECIMAL(5,2),            -- è›‹ç™½è³ªï¼ˆgï¼‰
    fat DECIMAL(5,2),                -- è„‚è‚ªï¼ˆgï¼‰
    carbs DECIMAL(5,2),              -- ç¢³æ°´åŒ–åˆç‰©ï¼ˆgï¼‰
    ingredients TEXT,                -- ä¸»è¦é£Ÿæï¼ˆJSONï¼‰
    description TEXT,                -- æè¿°
    image_url VARCHAR(512),          -- ç¤ºä¾‹åœ–ç‰‡URL
    created_at TIMESTAMP,
    updated_at TIMESTAMP
);

CREATE INDEX idx_food_country ON food_info(country);
CREATE INDEX idx_food_name ON food_info(name);
```

### æ¨¡å‹ç‰ˆæœ¬ç®¡ç†è¡¨ï¼ˆmodel_versionsï¼‰

```sql
CREATE TABLE model_versions (
    id INTEGER PRIMARY KEY,
    level INTEGER NOT NULL,          -- 1, 2, 3
    country VARCHAR(50),             -- ç¬¬ä¸‰å±¤æ¨¡å‹éœ€è¦
    version VARCHAR(50) NOT NULL,
    model_path VARCHAR(512) NOT NULL,
    accuracy DECIMAL(5,2),           -- é©—è­‰é›†æº–ç¢ºç‡
    training_date DATE,
    is_active BOOLEAN DEFAULT 0,
    created_at TIMESTAMP
);
```

---

## éƒ¨ç½²æ¶æ§‹

### æœå‹™æ¶æ§‹ï¼ˆNode.js çµ±ä¸€æ¶æ§‹ï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å‰ç«¯æ‡‰ç”¨   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP/HTTPS
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Node.js å¾Œç«¯æœå‹™           â”‚
â”‚  (Express API + TensorFlow.js)  â”‚
â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Express è·¯ç”±å±¤          â”‚ â”‚
â”‚  â”‚   - /api/food/recognize   â”‚ â”‚
â”‚  â”‚   - /api/food/images      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚              â”‚                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   TensorFlow.js æ¨ç†å±¤    â”‚ â”‚
â”‚  â”‚   - æ¨¡å‹åŠ è¼‰èˆ‡ç®¡ç†        â”‚ â”‚
â”‚  â”‚   - åœ–åƒé è™•ç†            â”‚ â”‚
â”‚  â”‚   - ä¸‰å±¤ç´šè¯æ¨ç†          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚              â”‚                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   æ•¸æ“šåº«å±¤                â”‚ â”‚
â”‚  â”‚   - é£Ÿç‰©ä¿¡æ¯æŸ¥è©¢          â”‚ â”‚
â”‚  â”‚   - è­˜åˆ¥çµæœå­˜å„²          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æ¨¡å‹å­˜å„²      â”‚
â”‚  (æ–‡ä»¶ç³»çµ±)     â”‚
â”‚  - models/      â”‚
â”‚    - level1/    â”‚
â”‚    - level2/    â”‚
â”‚    - level3/    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Node.js æ¨ç†æœå‹™å¯¦ç¾

#### æ ¸å¿ƒæ¨¡å¡Šçµæ§‹

```
server/
â”œâ”€â”€ food-recognition/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ ModelLoader.ts      # æ¨¡å‹åŠ è¼‰å™¨
â”‚   â”‚   â”œâ”€â”€ ImagePreprocessor.ts # åœ–åƒé è™•ç†
â”‚   â”‚   â””â”€â”€ RecognitionPipeline.ts # ä¸‰å±¤æ¨ç†ç®¡é“
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ DataLoader.ts       # æ•¸æ“šåŠ è¼‰
â”‚   â”‚   â”œâ”€â”€ Trainer.ts          # æ¨¡å‹è¨“ç·´
â”‚   â”‚   â””â”€â”€ Augmentation.ts    # æ•¸æ“šå¢å¼·
â”‚   â””â”€â”€ index.ts                  # å°å‡ºæ¥å£
```

#### TypeScript å¯¦ç¾ç¤ºä¾‹

```typescript
// server/food-recognition/models/ModelLoader.ts
import * as tf from "@tensorflow/tfjs-node";
// æˆ–ä½¿ç”¨ GPU ç‰ˆæœ¬ï¼š
// import * as tf from '@tensorflow/tfjs-node-gpu';
import path from "path";
import fs from "fs-extra";

export class ModelLoader {
  private level1Model: tf.LayersModel | null = null;
  private level2Model: tf.LayersModel | null = null;
  private countryModels: Map<string, tf.LayersModel> = new Map();

  /**
   * åŠ è¼‰ç¬¬ä¸€å±¤æ¨¡å‹ï¼ˆé£Ÿç‰©æª¢æ¸¬ï¼‰
   */
  async loadLevel1Model(modelPath: string): Promise<void> {
    const fullPath = path.resolve(modelPath);
    if (!fs.existsSync(fullPath)) {
      throw new Error(`æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: ${fullPath}`);
    }
    this.level1Model = await tf.loadLayersModel(
      `file://${fullPath}/model.json`
    );
    console.log("âœ… ç¬¬ä¸€å±¤æ¨¡å‹åŠ è¼‰æˆåŠŸ");
  }

  /**
   * åŠ è¼‰ç¬¬äºŒå±¤æ¨¡å‹ï¼ˆåœ‹å®¶åˆ†é¡ï¼‰
   */
  async loadLevel2Model(modelPath: string): Promise<void> {
    const fullPath = path.resolve(modelPath);
    this.level2Model = await tf.loadLayersModel(
      `file://${fullPath}/model.json`
    );
    console.log("âœ… ç¬¬äºŒå±¤æ¨¡å‹åŠ è¼‰æˆåŠŸ");
  }

  /**
   * åŠ è¼‰ç¬¬ä¸‰å±¤æ¨¡å‹ï¼ˆæŒ‰åœ‹å®¶ï¼‰
   */
  async loadCountryModel(country: string, modelPath: string): Promise<void> {
    const fullPath = path.resolve(modelPath);
    const model = await tf.loadLayersModel(`file://${fullPath}/model.json`);
    this.countryModels.set(country, model);
    console.log(`âœ… ${country} åœ‹å®¶æ¨¡å‹åŠ è¼‰æˆåŠŸ`);
  }

  getLevel1Model(): tf.LayersModel {
    if (!this.level1Model) {
      throw new Error("ç¬¬ä¸€å±¤æ¨¡å‹æœªåŠ è¼‰");
    }
    return this.level1Model;
  }

  getLevel2Model(): tf.LayersModel {
    if (!this.level2Model) {
      throw new Error("ç¬¬äºŒå±¤æ¨¡å‹æœªåŠ è¼‰");
    }
    return this.level2Model;
  }

  getCountryModel(country: string): tf.LayersModel {
    const model = this.countryModels.get(country);
    if (!model) {
      throw new Error(`${country} åœ‹å®¶æ¨¡å‹æœªåŠ è¼‰`);
    }
    return model;
  }
}
```

```typescript
// server/food-recognition/models/ImagePreprocessor.ts
import * as tf from "@tensorflow/tfjs-node";
import sharp from "sharp";
import { Readable } from "stream";

export class ImagePreprocessor {
  /**
   * å°‡åœ–åƒé è™•ç†ç‚ºæ¨¡å‹è¼¸å…¥æ ¼å¼
   * @param imageBuffer åœ–åƒç·©è¡å€
   * @param targetSize ç›®æ¨™å°ºå¯¸ [width, height]
   * @returns é è™•ç†å¾Œçš„å¼µé‡
   */
  async preprocessImage(
    imageBuffer: Buffer,
    targetSize: [number, number] = [224, 224]
  ): Promise<tf.Tensor4D> {
    // ä½¿ç”¨ sharp é€²è¡Œåœ–åƒè™•ç†
    const resizedBuffer = await sharp(imageBuffer)
      .resize(targetSize[0], targetSize[1], {
        fit: "fill",
        background: { r: 0, g: 0, b: 0 },
      })
      .toFormat("raw")
      .toBuffer();

    // è½‰æ›ç‚ºå¼µé‡
    const imageTensor = tf.node.decodeImage(imageBuffer);
    const resized = tf.image.resizeBilinear(imageTensor, targetSize);
    const normalized = resized.div(255.0); // æ­¸ä¸€åŒ–åˆ° [0, 1]
    const batched = normalized.expandDims(0); // æ·»åŠ æ‰¹æ¬¡ç¶­åº¦

    // æ¸…ç†ä¸­é–“å¼µé‡
    imageTensor.dispose();
    resized.dispose();
    normalized.dispose();

    return batched as tf.Tensor4D;
  }

  /**
   * æ‰¹é‡é è™•ç†åœ–åƒ
   */
  async preprocessBatch(
    imageBuffers: Buffer[],
    targetSize: [number, number] = [224, 224]
  ): Promise<tf.Tensor4D> {
    const preprocessed = await Promise.all(
      imageBuffers.map((buf) => this.preprocessImage(buf, targetSize))
    );
    return tf.concat(preprocessed, 0);
  }
}
```

```typescript
// server/food-recognition/models/RecognitionPipeline.ts
import * as tf from "@tensorflow/tfjs-node";
import { ModelLoader } from "./ModelLoader.js";
import { ImagePreprocessor } from "./ImagePreprocessor.js";
import { proxy } from "../../proxy.js";

export interface RecognitionResult {
  is_food: boolean;
  confidence?: number;
  country?: string;
  country_confidence?: number;
  food_name?: string;
  food_confidence?: number;
  calories?: number;
  ingredients?: string[];
  overall_confidence?: number;
  message?: string;
}

export class RecognitionPipeline {
  private modelLoader: ModelLoader;
  private preprocessor: ImagePreprocessor;

  constructor(modelLoader: ModelLoader, preprocessor: ImagePreprocessor) {
    this.modelLoader = modelLoader;
    this.preprocessor = preprocessor;
  }

  /**
   * ä¸‰å±¤ç´šè¯è­˜åˆ¥æµç¨‹
   */
  async recognizeFoodImage(imageBuffer: Buffer): Promise<RecognitionResult> {
    try {
      // é è™•ç†åœ–åƒ
      const imageTensor = await this.preprocessor.preprocessImage(
        imageBuffer,
        [224, 224]
      );

      // ç¬¬ä¸€å±¤ï¼šé£Ÿç‰©æª¢æ¸¬
      const level1Model = this.modelLoader.getLevel1Model();
      const level1Prediction = level1Model.predict(imageTensor) as tf.Tensor;
      const foodProbability = (await level1Prediction.data())[0];
      const isFood = foodProbability > 0.5;

      level1Prediction.dispose();

      if (!isFood) {
        imageTensor.dispose();
        return {
          is_food: false,
          confidence: 1 - foodProbability,
          message: "åœ–åƒä¸­æœªæª¢æ¸¬åˆ°é£Ÿç‰©",
        };
      }

      // ç¬¬äºŒå±¤ï¼šåœ‹å®¶è­˜åˆ¥
      const level2Model = this.modelLoader.getLevel2Model();
      const level2Prediction = level2Model.predict(imageTensor) as tf.Tensor;
      const countryProbabilities = await level2Prediction.data();
      const countryIndex = Array.from(countryProbabilities).indexOf(
        Math.max(...Array.from(countryProbabilities))
      );
      const countryConfidence = countryProbabilities[countryIndex];

      const countries = [
        "chinese",
        "japanese",
        "korean",
        "thai",
        "indian",
        "italian",
        "french",
        "mexican",
        "american",
        "others",
      ];
      const country = countries[countryIndex] || "unknown";

      level2Prediction.dispose();

      if (countryConfidence < 0.3) {
        imageTensor.dispose();
        return {
          is_food: true,
          country: "unknown",
          confidence: countryConfidence,
          message: "ç„¡æ³•è­˜åˆ¥é£Ÿç‰©ä¾†æºåœ‹å®¶",
        };
      }

      // ç¬¬ä¸‰å±¤ï¼šç´°ç²’åº¦è­˜åˆ¥ï¼ˆæ ¹æ“šåœ‹å®¶é¸æ“‡å°æ‡‰æ¨¡å‹ï¼‰
      const countryModel = this.modelLoader.getCountryModel(country);
      const level3Prediction = countryModel.predict(imageTensor) as tf.Tensor;
      const foodProbabilities = await level3Prediction.data();
      const foodIndex = Array.from(foodProbabilities).indexOf(
        Math.max(...Array.from(foodProbabilities))
      );
      const foodConfidence = foodProbabilities[foodIndex];

      level3Prediction.dispose();
      imageTensor.dispose();

      // å¾æ•¸æ“šåº«ç²å–é£Ÿç‰©è©³ç´°ä¿¡æ¯
      const foodInfo = await this.getFoodInfo(country, foodIndex);

      return {
        is_food: true,
        country,
        country_confidence: countryConfidence,
        food_name: foodInfo?.name,
        food_confidence: foodConfidence,
        calories: foodInfo?.calories,
        ingredients: foodInfo?.ingredients,
        overall_confidence: foodConfidence * countryConfidence,
      };
    } catch (error) {
      console.error("è­˜åˆ¥éç¨‹å‡ºéŒ¯:", error);
      throw error;
    }
  }

  /**
   * å¾æ•¸æ“šåº«ç²å–é£Ÿç‰©ä¿¡æ¯
   */
  private async getFoodInfo(country: string, foodIndex: number): Promise<any> {
    // é€™è£¡éœ€è¦æ ¹æ“šå¯¦éš›çš„æ•¸æ“šåº«çµæ§‹æŸ¥è©¢
    // å‡è¨­æœ‰ food_info è¡¨
    const foods = proxy.food_info?.filter((f) => f.country === country) || [];
    if (foods.length > foodIndex) {
      return foods[foodIndex];
    }
    return null;
  }
}
```

#### Express API è·¯ç”±é›†æˆ

```typescript
// server/server.ts (éƒ¨åˆ†ä»£ç¢¼)
import { ModelLoader } from "./food-recognition/models/ModelLoader.js";
import { ImagePreprocessor } from "./food-recognition/models/ImagePreprocessor.js";
import { RecognitionPipeline } from "./food-recognition/models/RecognitionPipeline.js";

// åˆå§‹åŒ–æ¨¡å‹åŠ è¼‰å™¨å’Œæ¨ç†ç®¡é“
const modelLoader = new ModelLoader();
const preprocessor = new ImagePreprocessor();
const recognitionPipeline = new RecognitionPipeline(modelLoader, preprocessor);

// å•Ÿå‹•æ™‚åŠ è¼‰æ¨¡å‹
async function initializeModels() {
  try {
    await modelLoader.loadLevel1Model("./models/level1");
    await modelLoader.loadLevel2Model("./models/level2");
    await modelLoader.loadCountryModel("chinese", "./models/level3/chinese");
    await modelLoader.loadCountryModel("japanese", "./models/level3/japanese");
    // ... åŠ è¼‰å…¶ä»–åœ‹å®¶æ¨¡å‹
    console.log("âœ… æ‰€æœ‰æ¨¡å‹åŠ è¼‰å®Œæˆ");
  } catch (error) {
    console.error("âŒ æ¨¡å‹åŠ è¼‰å¤±æ•—:", error);
  }
}

// API è·¯ç”±ï¼šé£Ÿç‰©è­˜åˆ¥
app.post(
  "/api/food/recognize",
  authenticateUser,
  upload.single("image"),
  async (req: any, res) => {
    try {
      if (!req.file) {
        return res.status(400).json({ error: "æœªæä¾›åœ–åƒæ–‡ä»¶" });
      }

      const imageBuffer = req.file.buffer;
      const result = await recognitionPipeline.recognizeFoodImage(imageBuffer);

      res.json(result);
    } catch (error) {
      console.error("è­˜åˆ¥éŒ¯èª¤:", error);
      res.status(500).json({ error: "è­˜åˆ¥å¤±æ•—" });
    }
  }
);

// å•Ÿå‹•æœå‹™å™¨æ™‚åˆå§‹åŒ–æ¨¡å‹
initializeModels();
```

---

## è¨“ç·´è¨ˆåŠƒ

### Phase 1ï¼šæ•¸æ“šæº–å‚™ï¼ˆ2-3 é€±ï¼‰

1. **æ•¸æ“šæ”¶é›†**

   - ä¸‹è¼‰å…¬é–‹æ•¸æ“šé›†ï¼ˆFood-101ã€ChineseFoodNet ç­‰ï¼‰
   - æ”¶é›†æœ¬åœ°é¤å»³åœ–ç‰‡
   - ç”¨æˆ¶ä¸Šå‚³åœ–ç‰‡æ¨™è¨»

2. **æ•¸æ“šæ¸…æ´—**

   - å»é™¤é‡è¤‡åœ–ç‰‡
   - è³ªé‡æª¢æŸ¥ï¼ˆæ¨¡ç³Šã€éæš—ç­‰ï¼‰
   - æ¨™è¨»é©—è­‰

3. **æ•¸æ“šåŠƒåˆ†**
   - è¨“ç·´é›†ï¼ˆ70%ï¼‰
   - é©—è­‰é›†ï¼ˆ15%ï¼‰
   - æ¸¬è©¦é›†ï¼ˆ15%ï¼‰

### Phase 2ï¼šç¬¬ä¸€å±¤æ¨¡å‹è¨“ç·´ï¼ˆ1-2 é€±ï¼‰

1. æ§‹å»ºé£Ÿç‰©æª¢æ¸¬æ¨¡å‹
2. è¨“ç·´å’Œèª¿å„ª
3. è©•ä¼°å’Œéƒ¨ç½²

### Phase 3ï¼šç¬¬äºŒå±¤æ¨¡å‹è¨“ç·´ï¼ˆ2-3 é€±ï¼‰

1. æ§‹å»ºåœ‹å®¶åˆ†é¡æ¨¡å‹
2. è¨“ç·´å’Œèª¿å„ª
3. è©•ä¼°å’Œéƒ¨ç½²

### Phase 4ï¼šç¬¬ä¸‰å±¤æ¨¡å‹è¨“ç·´ï¼ˆ4-6 é€±ï¼‰

1. ç‚ºä¸»è¦åœ‹å®¶ï¼ˆä¸­åœ‹ã€æ—¥æœ¬ï¼‰è¨“ç·´æ¨¡å‹
2. é€æ­¥æ“´å±•åˆ°å…¶ä»–åœ‹å®¶
3. æŒçºŒå„ªåŒ–å’Œè¿­ä»£

### Phase 5ï¼šé›†æˆèˆ‡å„ªåŒ–ï¼ˆ2-3 é€±ï¼‰

1. ä¸‰å±¤æ¨¡å‹é›†æˆ
2. æ€§èƒ½å„ªåŒ–
3. ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²

---

## è©•ä¼°æŒ‡æ¨™

### ç¬¬ä¸€å±¤ï¼ˆäºŒåˆ†é¡ï¼‰

- **æº–ç¢ºç‡ï¼ˆAccuracyï¼‰**ï¼š> 95%
- **ç²¾ç¢ºç‡ï¼ˆPrecisionï¼‰**ï¼š> 95%
- **å¬å›ç‡ï¼ˆRecallï¼‰**ï¼š> 95%
- **F1 åˆ†æ•¸**ï¼š> 0.95
- **æ¨ç†æ™‚é–“**ï¼š< 50msï¼ˆCPUï¼‰

### ç¬¬äºŒå±¤ï¼ˆå¤šåˆ†é¡ï¼‰

- **Top-1 æº–ç¢ºç‡**ï¼š> 80%
- **Top-3 æº–ç¢ºç‡**ï¼š> 90%
- **æ··æ·†çŸ©é™£åˆ†æ**ï¼šè­˜åˆ¥æ˜“æ··æ·†çš„åœ‹å®¶
- **æ¨ç†æ™‚é–“**ï¼š< 100msï¼ˆCPUï¼‰

### ç¬¬ä¸‰å±¤ï¼ˆç´°ç²’åº¦åˆ†é¡ï¼‰

- **Top-1 æº–ç¢ºç‡**ï¼š> 75%
- **Top-5 æº–ç¢ºç‡**ï¼š> 90%
- **æ¯é¡å¹³å‡æº–ç¢ºç‡**ï¼š> 70%
- **æ¨ç†æ™‚é–“**ï¼š< 200msï¼ˆCPUï¼‰

---

## æŒ‘æˆ°èˆ‡è§£æ±ºæ–¹æ¡ˆ

### æŒ‘æˆ° 1ï¼šæ•¸æ“šä¸å¹³è¡¡

**å•é¡Œ**ï¼šæŸäº›é£Ÿç‰©é¡åˆ¥æ¨£æœ¬æ•¸é‡é å°‘æ–¼å…¶ä»–é¡åˆ¥

**è§£æ±ºæ–¹æ¡ˆ**ï¼š

- æ•¸æ“šå¢å¼·ï¼ˆé‡å°å°‘æ¨£æœ¬é¡åˆ¥ï¼‰
- é¡åˆ¥æ¬Šé‡èª¿æ•´
- éæ¡æ¨£ï¼ˆSMOTEï¼‰æˆ–æ¬ æ¡æ¨£
- ç„¦é»æå¤±ï¼ˆFocal Lossï¼‰

### æŒ‘æˆ° 2ï¼šç´°ç²’åº¦åˆ†é¡é›£åº¦

**å•é¡Œ**ï¼šç›¸ä¼¼é£Ÿç‰©é›£ä»¥å€åˆ†ï¼ˆå¦‚ä¸åŒç¨®é¡çš„å£½å¸ï¼‰

**è§£æ±ºæ–¹æ¡ˆ**ï¼š

- ä½¿ç”¨æ›´æ·±çš„ç¶²çµ¡ï¼ˆResNet101ã€EfficientNet-B4ï¼‰
- æ³¨æ„åŠ›æ©Ÿåˆ¶ï¼ˆAttentionï¼‰
- å¤šå°ºåº¦ç‰¹å¾µèåˆ
- é›†æˆå­¸ç¿’

### æŒ‘æˆ° 3ï¼šè¨ˆç®—è³‡æºé™åˆ¶

**å•é¡Œ**ï¼šæ¨¡å‹æ¨ç†éœ€è¦è¼ƒå¤šè¨ˆç®—è³‡æº

**è§£æ±ºæ–¹æ¡ˆ**ï¼š

- æ¨¡å‹é‡åŒ–ï¼ˆINT8ï¼‰
- æ¨¡å‹å‰ªæ
- çŸ¥è­˜è’¸é¤¾ï¼ˆä½¿ç”¨å°æ¨¡å‹ï¼‰
- ç•°æ­¥æ¨ç†ï¼ˆéšŠåˆ—è™•ç†ï¼‰

### æŒ‘æˆ° 4ï¼šæ–°é£Ÿç‰©é¡åˆ¥è­˜åˆ¥

**å•é¡Œ**ï¼šæœªè¦‹éçš„é£Ÿç‰©ç„¡æ³•è­˜åˆ¥

**è§£æ±ºæ–¹æ¡ˆ**ï¼š

- é›¶æ¨£æœ¬å­¸ç¿’ï¼ˆZero-shot Learningï¼‰
- å°‘æ¨£æœ¬å­¸ç¿’ï¼ˆFew-shot Learningï¼‰
- æŒçºŒå­¸ç¿’ï¼ˆContinual Learningï¼‰
- ç”¨æˆ¶åé¥‹æ©Ÿåˆ¶ï¼ˆæ¨™è¨»æ–°é£Ÿç‰©ï¼‰

---

## åƒè€ƒè³‡æ–™

### å­¸è¡“è«–æ–‡

1. **ChineseFoodNet**: "ChineseFoodNet: A Large-scale Image Dataset for Chinese Food Recognition" (arXiv:1705.02743)
2. **DeepFood**: "DeepFood: Deep Learning-Based Food Image Recognition for Computer-Aided Dietary Assessment" (arXiv:1606.05675)
3. **Res-VMamba**: "Res-VMamba: Fine-grained Food Classification using Selective State Space Models" (arXiv:2402.15761)
4. **GCAM**: "Gaussian and Causal Attention Mechanism for Fine-grained Food Recognition" (arXiv:2403.12109)

### æ•¸æ“šé›†

- **Food-101**: https://www.vision.ee.ethz.ch/datasets_extra/food-101/
- **ChineseFoodNet**: https://github.com/liuziwei7/food-recognition
- **UECFOOD-256**: http://foodcam.mobi/
- **Vireo Food-172**: http://vireo.cs.cityu.edu.hk/research/food/

### å·¥å…·èˆ‡æ¡†æ¶

- **TensorFlow**: https://www.tensorflow.org/
- **Keras**: https://keras.io/
- **TensorFlow Lite**: https://www.tensorflow.org/lite
- **Albumentations**: https://albumentations.ai/ (æ•¸æ“šå¢å¼·)

---

## é™„éŒ„ï¼šä»£ç¢¼ç¤ºä¾‹

### å®Œæ•´çš„æ¨¡å‹æ§‹å»ºç¤ºä¾‹ï¼ˆNode.js/TypeScriptï¼‰

```typescript
// scripts/train/model-builder.ts
import * as tf from "@tensorflow/tfjs-node-gpu";

/**
 * æ§‹å»ºç´°ç²’åº¦é£Ÿç‰©åˆ†é¡æ¨¡å‹ï¼ˆç¬¬ä¸‰å±¤ï¼‰
 * ä½¿ç”¨é¡ä¼¼ EfficientNet çš„æ¶æ§‹
 */
export function buildFineGrainedModel(
  numClasses: number,
  inputShape: [number, number, number] = [380, 380, 3]
): tf.Sequential {
  const model = tf.sequential({
    layers: [
      // ç¬¬ä¸€çµ„å·ç©å¡Š
      tf.layers.conv2d({
        inputShape,
        filters: 32,
        kernelSize: 3,
        activation: "relu",
        padding: "same",
      }),
      tf.layers.batchNormalization(),
      tf.layers.maxPooling2d({ poolSize: 2 }),

      // ç¬¬äºŒçµ„å·ç©å¡Š
      tf.layers.conv2d({
        filters: 64,
        kernelSize: 3,
        activation: "relu",
        padding: "same",
      }),
      tf.layers.batchNormalization(),
      tf.layers.maxPooling2d({ poolSize: 2 }),

      // ç¬¬ä¸‰çµ„å·ç©å¡Š
      tf.layers.conv2d({
        filters: 128,
        kernelSize: 3,
        activation: "relu",
        padding: "same",
      }),
      tf.layers.batchNormalization(),
      tf.layers.maxPooling2d({ poolSize: 2 }),

      // ç¬¬å››çµ„å·ç©å¡Š
      tf.layers.conv2d({
        filters: 256,
        kernelSize: 3,
        activation: "relu",
        padding: "same",
      }),
      tf.layers.batchNormalization(),
      tf.layers.maxPooling2d({ poolSize: 2 }),

      // å…¨å±€å¹³å‡æ± åŒ–
      tf.layers.globalAveragePooling2d(),

      // åˆ†é¡é ­
      tf.layers.dense({ units: 1024, activation: "relu" }),
      tf.layers.batchNormalization(),
      tf.layers.dropout({ rate: 0.5 }),
      tf.layers.dense({ units: 512, activation: "relu" }),
      tf.layers.batchNormalization(),
      tf.layers.dropout({ rate: 0.3 }),
      tf.layers.dense({ units: numClasses, activation: "softmax" }),
    ],
  });

  return model;
}

// ç·¨è­¯æ¨¡å‹
const model = buildFineGrainedModel(208); // 208 ç¨®ä¸­åœ‹èœå“
model.compile({
  optimizer: tf.train.adam(0.0001),
  loss: "categoricalCrossentropy",
  metrics: ["accuracy"],
});

// è‡ªå®šç¾© Top-5 æº–ç¢ºç‡æŒ‡æ¨™
const top5Accuracy = {
  f: (yTrue: tf.Tensor, yPred: tf.Tensor) => {
    const top5 = tf.topk(yPred, 5);
    const indices = top5.indices;
    const values = top5.values;
    // è¨ˆç®— Top-5 æº–ç¢ºç‡é‚è¼¯
    return tf.mean(tf.cast(tf.greater(values, 0.5), "float32"));
  },
  n: "top5Accuracy",
};
```

### æ•¸æ“šå¢å¼·å¯¦ç¾ï¼ˆNode.jsï¼‰

```typescript
// scripts/train/augmentation.ts
import * as tf from "@tensorflow/tfjs-node";
import sharp from "sharp";

export class ImageAugmentation {
  /**
   * éš¨æ©Ÿæ—‹è½‰åœ–åƒ
   */
  async rotateImage(buffer: Buffer, angle: number): Promise<Buffer> {
    return await sharp(buffer).rotate(angle).toBuffer();
  }

  /**
   * éš¨æ©Ÿæ°´å¹³ç¿»è½‰
   */
  async flipHorizontal(buffer: Buffer): Promise<Buffer> {
    return await sharp(buffer).flip().toBuffer();
  }

  /**
   * èª¿æ•´äº®åº¦
   */
  async adjustBrightness(buffer: Buffer, factor: number): Promise<Buffer> {
    return await sharp(buffer).modulate({ brightness: factor }).toBuffer();
  }

  /**
   * éš¨æ©Ÿè£å‰ªå’Œç¸®æ”¾
   */
  async randomCropAndResize(
    buffer: Buffer,
    targetSize: [number, number]
  ): Promise<Buffer> {
    const metadata = await sharp(buffer).metadata();
    const width = metadata.width || 224;
    const height = metadata.height || 224;

    // éš¨æ©Ÿè£å‰ªå€åŸŸ
    const cropSize = Math.min(width, height);
    const x = Math.floor(Math.random() * (width - cropSize));
    const y = Math.floor(Math.random() * (height - cropSize));

    return await sharp(buffer)
      .extract({ left: x, top: y, width: cropSize, height: cropSize })
      .resize(targetSize[0], targetSize[1])
      .toBuffer();
  }

  /**
   * æ‡‰ç”¨éš¨æ©Ÿå¢å¼·
   */
  async applyRandomAugmentation(buffer: Buffer): Promise<Buffer> {
    let augmented = buffer;

    // 50% æ¦‚ç‡æ°´å¹³ç¿»è½‰
    if (Math.random() > 0.5) {
      augmented = await this.flipHorizontal(augmented);
    }

    // éš¨æ©Ÿæ—‹è½‰ Â±30 åº¦
    if (Math.random() > 0.5) {
      const angle = (Math.random() - 0.5) * 60; // -30 åˆ° +30 åº¦
      augmented = await this.rotateImage(augmented, angle);
    }

    // éš¨æ©Ÿäº®åº¦èª¿æ•´
    if (Math.random() > 0.5) {
      const brightness = 0.8 + Math.random() * 0.4; // 0.8 åˆ° 1.2
      augmented = await this.adjustBrightness(augmented, brightness);
    }

    return augmented;
  }
}

// åœ¨æ•¸æ“šåŠ è¼‰æ™‚æ‡‰ç”¨å¢å¼·
export async function augmentDataset(
  images: Buffer[],
  labels: number[]
): Promise<{ images: Buffer[]; labels: number[] }> {
  const augmentation = new ImageAugmentation();
  const augmentedImages: Buffer[] = [];
  const augmentedLabels: number[] = [];

  for (let i = 0; i < images.length; i++) {
    // åŸå§‹åœ–åƒ
    augmentedImages.push(images[i]);
    augmentedLabels.push(labels[i]);

    // å¢å¼·å¾Œçš„åœ–åƒ
    const augmented = await augmentation.applyRandomAugmentation(images[i]);
    augmentedImages.push(augmented);
    augmentedLabels.push(labels[i]);
  }

  return { images: augmentedImages, labels: augmentedLabels };
}
```

### å®Œæ•´çš„è¨“ç·´è…³æœ¬ç¤ºä¾‹

```typescript
// scripts/train/train-complete.ts
import * as tf from "@tensorflow/tfjs-node-gpu";
import { buildFineGrainedModel } from "./model-builder.js";
import { DataLoader } from "./data-loader.js";
import { augmentDataset } from "./augmentation.js";
import path from "path";

async function trainComplete() {
  console.log("ğŸš€ é–‹å§‹å®Œæ•´è¨“ç·´æµç¨‹...");

  // 1. æº–å‚™æ•¸æ“š
  const dataLoader = new DataLoader();
  const trainData = await dataLoader.loadFineGrainedData({
    dataPath: "./data/level3-fine-grained/chinese",
    batchSize: 16,
    imageSize: [380, 380],
  });

  // 2. æ•¸æ“šå¢å¼·
  const augmentedData = await augmentDataset(
    trainData.images,
    trainData.labels
  );

  // 3. æ§‹å»ºæ¨¡å‹
  const model = buildFineGrainedModel(208); // 208 ç¨®ä¸­åœ‹èœå“

  // 4. ç·¨è­¯æ¨¡å‹
  model.compile({
    optimizer: tf.train.adam(0.0001),
    loss: "categoricalCrossentropy",
    metrics: ["accuracy"],
  });

  // 5. è¨“ç·´é…ç½®
  const epochs = 50;
  let bestValAccuracy = 0;
  let patience = 10;
  let patienceCounter = 0;

  // 6. è¨“ç·´å¾ªç’°
  for (let epoch = 0; epoch < epochs; epoch++) {
    console.log(`\nEpoch ${epoch + 1}/${epochs}`);

    // è¨“ç·´ä¸€å€‹ epoch
    const history = await model.fitDataset(trainData.dataset, {
      epochs: 1,
      validationData: trainData.valDataset,
      callbacks: {
        onEpochEnd: async (epoch, logs) => {
          const valAcc = logs?.val_acc as number;
          console.log(
            `  Loss: ${logs?.loss?.toFixed(4)}, Acc: ${logs?.acc?.toFixed(
              4
            )}, ` +
              `Val Loss: ${logs?.val_loss?.toFixed(
                4
              )}, Val Acc: ${valAcc?.toFixed(4)}`
          );

          // Early stopping
          if (valAcc > bestValAccuracy) {
            bestValAccuracy = valAcc;
            patienceCounter = 0;
            // ä¿å­˜æœ€ä½³æ¨¡å‹
            await model.save(`file://./models/level3/chinese/best`);
          } else {
            patienceCounter++;
            if (patienceCounter >= patience) {
              console.log("â¹ï¸  æ—©åœè§¸ç™¼ï¼Œè¨“ç·´çµæŸ");
              return;
            }
          }
        },
      },
    });
  }

  // 7. ä¿å­˜æœ€çµ‚æ¨¡å‹
  await model.save(`file://./models/level3/chinese/final`);
  console.log("âœ… è¨“ç·´å®Œæˆï¼");
}

// åŸ·è¡Œè¨“ç·´
trainComplete().catch(console.error);
```

### æ¨¡å‹è½‰æ›å·¥å…·ï¼ˆPython â†’ TensorFlow.jsï¼‰

å¦‚æœéœ€è¦ä½¿ç”¨ Python è¨“ç·´æ¨¡å‹ï¼Œç„¶å¾Œè½‰æ›ç‚º TensorFlow.js æ ¼å¼ï¼š

```bash
# å®‰è£è½‰æ›å·¥å…·
pnpm add -D @tensorflow/tfjs-converter

# è½‰æ› Keras æ¨¡å‹
tensorflowjs_converter \
  --input_format=keras \
  --output_format=tfjs_layers_model \
  ./models/level1_food_detection.h5 \
  ./models/level1/

# è½‰æ› SavedModel
tensorflowjs_converter \
  --input_format=tf_saved_model \
  --output_format=tfjs_graph_model \
  ./models/saved_model \
  ./models/tfjs_model/
```

```typescript
// åœ¨ Node.js ä¸­åŠ è¼‰è½‰æ›å¾Œçš„æ¨¡å‹
import * as tf from "@tensorflow/tfjs-node";

const model = await tf.loadLayersModel("file://./models/level1/model.json");
```

---

## ç¸½çµ

æœ¬æ¶æ§‹è¨­è¨ˆæ¡ç”¨ä¸‰å±¤ç´šè¯åˆ†é¡ç­–ç•¥ï¼Œå¾ç²—ç²’åº¦åˆ°ç´°ç²’åº¦é€æ­¥è­˜åˆ¥é£Ÿç‰©åœ–åƒã€‚é€šéåˆç†çš„æ¨¡å‹é¸æ“‡ã€æ•¸æ“šé›†è¨­è¨ˆå’Œè¨“ç·´ç­–ç•¥ï¼Œå¯ä»¥æ§‹å»ºä¸€å€‹é«˜æ•ˆã€æº–ç¢ºçš„é£Ÿç‰©è­˜åˆ¥ç³»çµ±ã€‚

**é—œéµæˆåŠŸå› ç´ **ï¼š

1. é«˜è³ªé‡çš„æ•¸æ“šé›†ï¼ˆæ•¸é‡å……è¶³ã€æ¨™è¨»æº–ç¢ºï¼‰
2. åˆé©çš„æ¨¡å‹æ¶æ§‹ï¼ˆå¹³è¡¡æº–ç¢ºç‡å’Œæ•ˆç‡ï¼‰
3. å……åˆ†çš„æ•¸æ“šå¢å¼·å’Œæ­£å‰‡åŒ–
4. æŒçºŒçš„æ¨¡å‹å„ªåŒ–å’Œè¿­ä»£

**ä¸‹ä¸€æ­¥è¡Œå‹•**ï¼š

1. é–‹å§‹æ•¸æ“šæ”¶é›†å’Œæ¨™è¨»å·¥ä½œ
2. æ­å»ºè¨“ç·´ç’°å¢ƒï¼ˆGPU æœå‹™å™¨æˆ–é›²ç«¯ï¼‰
3. å¯¦ç¾ç¬¬ä¸€å±¤æ¨¡å‹ï¼ˆé£Ÿç‰©æª¢æ¸¬ï¼‰
4. é€æ­¥æ“´å±•åˆ°ç¬¬äºŒå±¤å’Œç¬¬ä¸‰å±¤

---

## å¯¦ä½œ TODO åˆ—è¡¨

### Phase 1: åŸºç¤è¨­æ–½æ­å»º

- [x] **TODO-1**: å®‰è£å¿…è¦çš„ä¾è³´åŒ…

  - `@tensorflow/tfjs-node` æˆ– `@tensorflow/tfjs-node-gpu`
  - `fs-extra`
  - `image-dataset`
  - `node-cache`ï¼ˆå¯é¸ï¼Œç”¨æ–¼ç·©å­˜ï¼‰
  - `p-queue`ï¼ˆå¯é¸ï¼Œç”¨æ–¼éšŠåˆ—ç®¡ç†ï¼‰

- [x] **TODO-2**: å‰µå»ºåŸºç¤ç›®éŒ„çµæ§‹
  - `server/food-recognition/models/` - æ¨¡å‹ç›¸é—œæ¨¡å¡Š âœ…
  - `server/food-recognition/training/` - è¨“ç·´ç›¸é—œæ¨¡å¡Š âœ…
  - `scripts/train/` - è¨“ç·´è…³æœ¬ âœ…
  - `scripts/data-collection/` - æ•¸æ“šæ”¶é›†è…³æœ¬ âœ…
  - `models/level1/`, `models/level2/`, `models/level3/` - æ¨¡å‹å­˜å„²ç›®éŒ„ âœ…

### Phase 2: æ ¸å¿ƒæ¨¡å¡Šå¯¦ç¾

- [x] **TODO-3**: å¯¦ç¾ `ImagePreprocessor.ts`

  - åœ–åƒé è™•ç†ï¼ˆç¸®æ”¾ã€æ­¸ä¸€åŒ–ï¼‰âœ…
  - æ‰¹é‡é è™•ç†æ”¯æŒ âœ…
  - èˆ‡ sharp é›†æˆ âœ…

- [x] **TODO-4**: å¯¦ç¾ `ModelLoader.ts`

  - æ¨¡å‹åŠ è¼‰å’Œç·©å­˜ âœ…
  - æ”¯æŒä¸‰å±¤æ¨¡å‹åŠ è¼‰ âœ…
  - éŒ¯èª¤è™•ç†å’Œæ—¥èªŒè¨˜éŒ„ âœ…

- [x] **TODO-5**: å¯¦ç¾ `RecognitionPipeline.ts`
  - ä¸‰å±¤ç´šè¯æ¨ç†æµç¨‹ âœ…
  - æ—©æœŸæ‹’çµ•æ©Ÿåˆ¶ âœ…
  - çµæœæ•´åˆå’Œæ ¼å¼åŒ– âœ…

### Phase 3: API é›†æˆ

- [x] **TODO-6**: åœ¨ `server.ts` ä¸­é›†æˆé£Ÿç‰©è­˜åˆ¥ API
  - `POST /api/food/recognize-tfjs` - å–®åœ–è­˜åˆ¥ï¼ˆTensorFlow.jsï¼‰
  - `POST /api/food/recognize-tfjs-batch` - æ‰¹é‡è­˜åˆ¥
  - `GET /api/food/models/status` - ç²å–æ¨¡å‹åŠ è¼‰ç‹€æ…‹
  - èˆ‡ç¾æœ‰èªè­‰ç³»çµ±é›†æˆ
  - æ¨¡å‹è‡ªå‹•åˆå§‹åŒ–ï¼ˆæœå‹™å™¨å•Ÿå‹•æ™‚ï¼‰

### Phase 4: è¨“ç·´åŸºç¤è¨­æ–½

- [x] **TODO-7**: å¯¦ç¾ `DataLoader.ts`

  - å¾æ–‡ä»¶ç³»çµ±åŠ è¼‰åœ–åƒæ•¸æ“šé›†
  - æ•¸æ“šåŠƒåˆ†ï¼ˆè¨“ç·´/é©—è­‰/æ¸¬è©¦ï¼‰
  - æ‰¹é‡æ•¸æ“šç”Ÿæˆ
  - æ”¯æŒåˆ†é¡å’ŒäºŒåˆ†é¡æ•¸æ“šé›†
  - æ•¸æ“šé›†çµ±è¨ˆä¿¡æ¯

- [x] **TODO-8**: å¯¦ç¾ `model-builder.ts`

  - ç¬¬ä¸€å±¤æ¨¡å‹æ§‹å»ºï¼ˆé£Ÿç‰©æª¢æ¸¬ï¼‰- è¼•é‡ç´š CNN
  - ç¬¬äºŒå±¤æ¨¡å‹æ§‹å»ºï¼ˆåœ‹å®¶åˆ†é¡ï¼‰- ResNet é¢¨æ ¼
  - ç¬¬ä¸‰å±¤æ¨¡å‹æ§‹å»ºï¼ˆç´°ç²’åº¦åˆ†é¡ï¼‰- æ·±åº¦ CNN
  - æ¨¡å‹ç·¨è­¯åŠŸèƒ½

- [x] **TODO-9**: å¯¦ç¾ `augmentation.ts`
  - åœ–åƒå¢å¼·åŠŸèƒ½ï¼ˆæ—‹è½‰ã€ç¿»è½‰ã€äº®åº¦ã€é£½å’Œåº¦ç­‰ï¼‰
  - æ‰¹é‡å¢å¼·æ”¯æŒ
  - TensorFlow.js å¼µé‡ç´šå¢å¼·ï¼ˆæ›´é«˜æ•ˆï¼‰
  - å…©ç¨®å¢å¼·æ–¹å¼ï¼šsharpï¼ˆæ–‡ä»¶ç´šï¼‰å’Œ TensorFlow.jsï¼ˆå¼µé‡ç´šï¼‰

### Phase 5: è¨“ç·´è…³æœ¬

- [x] **TODO-10**: å‰µå»ºè¨“ç·´è…³æœ¬
  - `scripts/train/train-level1.ts` - ç¬¬ä¸€å±¤æ¨¡å‹è¨“ç·´ï¼ˆäºŒåˆ†é¡ï¼‰
  - `scripts/train/train-level2.ts` - ç¬¬äºŒå±¤æ¨¡å‹è¨“ç·´ï¼ˆå¤šåˆ†é¡ï¼‰
  - `scripts/train/train-level3.ts` - ç¬¬ä¸‰å±¤æ¨¡å‹è¨“ç·´ï¼ˆç´°ç²’åº¦ï¼ŒæŒ‰åœ‹å®¶ï¼‰
  - è¨“ç·´é…ç½®å’Œåƒæ•¸ç®¡ç†
  - Early stopping æ©Ÿåˆ¶
  - è¨“ç·´æ­·å²è¨˜éŒ„
  - æ¨¡å‹è©•ä¼°å’Œä¿å­˜
  - å·²æ·»åŠ åˆ° `package.json` è…³æœ¬ï¼š`train:level1`, `train:level2`, `train:level3`

### Phase 6: æ•¸æ“šåº«èˆ‡æ¨¡å‹ç®¡ç†

- [ ] **TODO-11**: æ›´æ–°æ•¸æ“šåº« schema

  - å‰µå»º `food_info` è¡¨ï¼ˆå­˜å„²é£Ÿç‰©è©³ç´°ä¿¡æ¯ï¼šåç¨±ã€å¡è·¯é‡Œã€é£Ÿæç­‰ï¼‰
  - å‰µå»º `model_versions` è¡¨ï¼ˆè¿½è¹¤æ¨¡å‹ç‰ˆæœ¬å’Œæ€§èƒ½æŒ‡æ¨™ï¼‰
  - æ•¸æ“šé·ç§»è…³æœ¬
  - èˆ‡ç¾æœ‰ `better-sqlite3-proxy` é›†æˆ

- [ ] **TODO-12**: å¯¦ç¾æ¨¡å‹ç‰ˆæœ¬ç®¡ç†
  - æ¨¡å‹ç‰ˆæœ¬è¿½è¹¤ï¼ˆç‰ˆæœ¬è™Ÿã€è¨“ç·´æ—¥æœŸã€æº–ç¢ºç‡ç­‰ï¼‰
  - æ¨¡å‹åˆ‡æ›å’Œå›æ»¾ï¼ˆæ”¯æŒåˆ‡æ›åˆ°ä¸åŒç‰ˆæœ¬çš„æ¨¡å‹ï¼‰
  - æ€§èƒ½æŒ‡æ¨™è¨˜éŒ„ï¼ˆæº–ç¢ºç‡ã€æ¨ç†æ™‚é–“ç­‰ï¼‰
  - API ç«¯é»ï¼š`GET /api/food/models/versions`, `POST /api/food/models/switch`

### Phase 7: æ¸¬è©¦èˆ‡å„ªåŒ–

- [x] **TODO-13**: å‰µå»ºæ¸¬è©¦é é¢ï¼ˆåŠŸèƒ½æ¸¬è©¦ï¼‰
  - âœ… æ¸¬è©¦é é¢ï¼š`food-recognition-test.html`
  - âœ… API é€£æ¥æ¸¬è©¦
  - âœ… æ¨¡å‹ç‹€æ…‹æŸ¥è©¢
  - âœ… åœ–åƒé è™•ç†æ¸¬è©¦
  - âœ… æ¨ç†æµç¨‹æ¸¬è©¦
  - âœ… æ•¸æ“šçµ±è¨ˆï¼ˆåªè®€ï¼Œä¸å½±éŸ¿æ•¸æ“šåº«ï¼‰
  - âœ… ç³»çµ±å¥åº·æª¢æŸ¥
  - âœ… è¨ªå•åœ°å€ï¼š`http://localhost:3000/food-recognition-test.html`

- [ ] **TODO-14**: å–®å…ƒæ¸¬è©¦ï¼ˆä»£ç¢¼ç´šæ¸¬è©¦ï¼‰

  - åœ–åƒé è™•ç†å–®å…ƒæ¸¬è©¦
  - æ¨¡å‹åŠ è¼‰å–®å…ƒæ¸¬è©¦
  - æ¨ç†æµç¨‹å–®å…ƒæ¸¬è©¦

- [ ] **TODO-15**: æ€§èƒ½å„ªåŒ–

  - GPU åŠ é€Ÿé©—è­‰
  - ç·©å­˜æ©Ÿåˆ¶å¯¦ç¾
  - æ‰¹é‡æ¨ç†å„ªåŒ–

- [ ] **TODO-16**: æ–‡æª”å®Œå–„
  - API æ–‡æª”
  - ä½¿ç”¨ç¤ºä¾‹
  - éƒ¨ç½²æŒ‡å—

---

**ç•¶å‰é€²åº¦**: Phase 5 + æ•¸æ“šæ”¶é›†å®Œæˆ âœ…

**å·²å®Œæˆéšæ®µ**:

- âœ… Phase 1: åŸºç¤è¨­æ–½æ­å»º
- âœ… Phase 2: æ ¸å¿ƒæ¨¡å¡Šå¯¦ç¾
- âœ… Phase 3: API é›†æˆ
- âœ… Phase 4: è¨“ç·´åŸºç¤è¨­æ–½
- âœ… Phase 5: è¨“ç·´è…³æœ¬
- âœ… æ•¸æ“šæ”¶é›†ï¼šä¸‹è¼‰å’Œçµ„ç¹”è…³æœ¬ã€åœ–ç‰‡é è™•ç†

**æœªå®Œæˆéšæ®µ**:

- â³ Phase 6: æ•¸æ“šåº«èˆ‡æ¨¡å‹ç®¡ç†ï¼ˆ2 å€‹ TODOï¼‰
- â³ Phase 7: æ¸¬è©¦èˆ‡å„ªåŒ–ï¼ˆ3 å€‹ TODOï¼‰

---

## ä¸‹ä¸€æ­¥å¯¦ä½œè¨ˆåŠƒ

### å„ªå…ˆç´š 1ï¼šæ•¸æ“šåº« Schemaï¼ˆPhase 6 - TODO-11ï¼‰

**ç›®æ¨™**ï¼šå‰µå»ºæ•¸æ“šåº«è¡¨ä¾†å­˜å„²é£Ÿç‰©ä¿¡æ¯å’Œæ¨¡å‹ç‰ˆæœ¬

**éœ€è¦å¯¦ä½œ**ï¼š

1. **food_info è¡¨**
   ```sql
   CREATE TABLE food_info (
     id INTEGER PRIMARY KEY,
     name VARCHAR(255) NOT NULL,
     name_en VARCHAR(255),
     country VARCHAR(50) NOT NULL,
     category VARCHAR(100),
     calories INTEGER,
     protein DECIMAL(5,2),
     fat DECIMAL(5,2),
     carbs DECIMAL(5,2),
     ingredients TEXT,
     description TEXT,
     created_at TIMESTAMP,
     updated_at TIMESTAMP
   );
   ```

2. **model_versions è¡¨**
   ```sql
   CREATE TABLE model_versions (
     id INTEGER PRIMARY KEY,
     level INTEGER NOT NULL,
     country VARCHAR(50),
     version VARCHAR(50) NOT NULL,
     model_path VARCHAR(512) NOT NULL,
     accuracy DECIMAL(5,2),
     training_date DATE,
     is_active BOOLEAN DEFAULT 0,
     created_at TIMESTAMP
   );
   ```

3. **æ•¸æ“šé·ç§»è…³æœ¬**
   - ä½¿ç”¨ç¾æœ‰çš„ `knex` é·ç§»ç³»çµ±
   - æ›´æ–° `erd.txt` å’Œç”Ÿæˆ proxy

### å„ªå…ˆç´š 2ï¼šæ¨¡å‹ç‰ˆæœ¬ç®¡ç†ï¼ˆPhase 6 - TODO-12ï¼‰

**ç›®æ¨™**ï¼šå¯¦ç¾æ¨¡å‹ç‰ˆæœ¬è¿½è¹¤å’Œç®¡ç†åŠŸèƒ½

**éœ€è¦å¯¦ä½œ**ï¼š

1. **ModelVersionManager é¡**
   - è¨˜éŒ„æ¨¡å‹ç‰ˆæœ¬ä¿¡æ¯
   - åˆ‡æ›æ´»å‹•æ¨¡å‹
   - æŸ¥è©¢ç‰ˆæœ¬æ­·å²

2. **API ç«¯é»**
   - `GET /api/food/models/versions` - ç²å–æ‰€æœ‰ç‰ˆæœ¬
   - `POST /api/food/models/switch` - åˆ‡æ›æ¨¡å‹ç‰ˆæœ¬
   - `GET /api/food/models/current` - ç²å–ç•¶å‰æ´»å‹•æ¨¡å‹

### å„ªå…ˆç´š 3ï¼šæ€§èƒ½å„ªåŒ–ï¼ˆPhase 7 - TODO-14ï¼‰

**ç›®æ¨™**ï¼šå„ªåŒ–æ¨ç†æ€§èƒ½

**éœ€è¦å¯¦ä½œ**ï¼š

1. **ç·©å­˜æ©Ÿåˆ¶**
   - ä½¿ç”¨ `node-cache` ç·©å­˜è­˜åˆ¥çµæœ
   - åŸºæ–¼åœ–ç‰‡å“ˆå¸Œçš„ç·©å­˜éµ

2. **æ‰¹é‡æ¨ç†å„ªåŒ–**
   - æ”¹é€²æ‰¹é‡è™•ç†é‚è¼¯
   - GPU åŠ é€Ÿé©—è­‰

### å„ªå…ˆç´š 4ï¼šæ¸¬è©¦ï¼ˆPhase 7 - TODO-13ï¼‰

**ç›®æ¨™**ï¼šç¢ºä¿ç³»çµ±ç©©å®šæ€§

**éœ€è¦å¯¦ä½œ**ï¼š

1. **å–®å…ƒæ¸¬è©¦**
   - åœ–åƒé è™•ç†æ¸¬è©¦
   - æ¨¡å‹åŠ è¼‰æ¸¬è©¦
   - æ¨ç†æµç¨‹æ¸¬è©¦

### å„ªå…ˆç´š 5ï¼šæ–‡æª”ï¼ˆPhase 7 - TODO-15ï¼‰

**ç›®æ¨™**ï¼šå®Œå–„ä½¿ç”¨æ–‡æª”

**éœ€è¦å¯¦ä½œ**ï¼š

1. **API æ–‡æª”**
2. **ä½¿ç”¨ç¤ºä¾‹**
3. **éƒ¨ç½²æŒ‡å—**

---

## ç¸½çµ

**å·²å®Œæˆ**ï¼š12/17 å€‹ TODOï¼ˆ70.6%ï¼‰

**å¾…å®Œæˆ**ï¼š5 å€‹ TODO
- æ•¸æ“šåº« Schemaï¼ˆ2 å€‹ï¼‰
- æ¸¬è©¦èˆ‡å„ªåŒ–ï¼ˆ3 å€‹ï¼‰

**å»ºè­°ä¸‹ä¸€æ­¥**ï¼šå„ªå…ˆå®Œæˆ Phase 6ï¼ˆæ•¸æ“šåº«èˆ‡æ¨¡å‹ç®¡ç†ï¼‰ï¼Œé€™æ¨£ç³»çµ±æ‰èƒ½å®Œæ•´å­˜å„²å’ŒæŸ¥è©¢é£Ÿç‰©ä¿¡æ¯ã€‚
